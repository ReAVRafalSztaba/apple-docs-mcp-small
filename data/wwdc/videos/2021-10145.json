{
  "id": "10145",
  "year": "2021",
  "url": "https://developer.apple.com/videos/play/wwdc2021/10145/",
  "title": "Evaluate videos with the Advanced Video Quality Tool",
  "speakers": [],
  "duration": "",
  "topics": [
    "Audio & Video",
    "Developer Tools"
  ],
  "hasTranscript": true,
  "hasCode": false,
  "transcript": {
    "fullText": "♪ Bass music playing ♪  ♪ Pranav Sodhani: Hello and welcome to WWDC! My name is Pranav, and I am part of the Display and Color Technologies team at Apple.\n\nIn this talk, we will introduce a video quality tool and show how you can use it to evaluate perceptual quality of compressed videos in your apps or content creation workflows All right.\n\nLet's start by looking at a typical video delivery workflow.\n\nIn such a workflow, the high-quality source video undergoes video compression and, optionally, video downscaling to generate videos with lower bit rates.\n\nAnd these low-bit rate videos can then be easily delivered over bandwidth-constrained networks.\n\nA few possible ways to use such workflows include AVFoundation APIs such as AVAssetWriter, apps such as Compressor, or it can be one of your own video compression workflows.\n\nNow, downscaling and compression can add video coding and scaling artifacts.\n\nAnd this will impair the source video and create visible artifacts.\n\nOne example of such artifact is blockiness in the compressed video, which is shown in the frame on the right side.\n\nAnother example is when the video appears blurry and video details start disappearing.\n\nSuch artifacts can adversely affect a consumer's video quality experience.\n\nWe know that consumers are expecting a high-quality video experience.\n\nSo it's important to deliver on this expectation.\n\nNow, the first step to do this is to evaluate the quality of your delivered content.\n\nAnd the most accurate way of doing this is to have real people watch the videos and rate them on a video quality scale.\n\nBut this is very time consuming and not scalable if you want to evaluate a high volume of videos.\n\nFortunately, there's another way.\n\nWhat we need here is an objective way to characterize video quality, so that we can automate the process for speed and scalability.\n\nIn such a setup, the perceptual video quality tool will take the compressed video and the source video as input and output a video quality score.\n\nThis score can be a floating point number in the range of one to five and mimic how real people would have rated the compressed video.\n\nToday, we are very excited to enable our developers with such a perceptual video quality tool.\n\nWe are calling it the Advanced Video Quality Tool or AVQT in short.\n\nLet's learn more about AVQT.\n\nSo what exactly is AVQT? Well, AVQT comes as a macOS command line executable.\n\nAnd it attempts to mimic how real people rate quality of compressed videos.\n\nYou can use AVQT to compute both frame level and segment level scores, where a segment is typically a few seconds long.\n\nAnd, of course, we have added support for all AVFoundation-based video formats in AVQT.\n\nThis includes SDR, as well as HDR video formats such as HDR10, HLG, and Dolby Vision.\n\nNext, we want to discuss three key attributes of AVQT that make it very useful across applications.\n\nFirst, we will see how well AVQT aligns with human perception.\n\nThen we will talk about AVQT's computational speed.\n\nAnd finally, we will show why viewing setup awareness is important when predicting video quality.\n\nLet's get into details for each of these.\n\nAVQT correlates well with human opinions on video quality.\n\nAnd it works well across content types, such as animation, natural scenes, or sports.\n\nWe have found that traditional video quality metrics such as PSNR and structural similarity -- or SSIM in short -- typically do not work very well across content types.\n\nLet's look at one example.\n\nNow, this is a frame from a high-quality sports clip, which is our first source video.\n\nLet's look at the same frame in the compressed video.\n\nYou can see that the frame does appear to be of sufficiently high perceptual quality.\n\nRightly so, it gets a PSNR score of around 35 and an AVQT score of 4.4.\n\nNext, we go with the same exercise for our second source video.\n\nThe compressed video in this case seems to have visible artifacts.\n\nIn particular, you can see some artifacts on the face of the person.\n\nInterestingly, it gets the same PSNR score of around 35, but this time AVQT rates it around 2.5, implying poor quality.\n\nWe think the AVQT score is the correct prediction here.\n\nNote that this is just one example we have picked to illustrate what can go wrong in cross-content evaluations.\n\nWe wanted to test AVQT's perceptual accuracy on a diverse set of videos.\n\nSo we evaluated it on publicly available video quality datasets.\n\nThese datasets include source videos, compressed videos, and video quality scores provided by human subjects.\n\nHere, we will show you the results on two datasets: Waterloo IVC 4K and VQEG HD3.\n\nThe Waterloo IVC dataset includes 20 source videos and 480 compressed videos, spanning both coding and scaling artifacts.\n\nIt covers four different video resolutions and two different video standards.\n\nThe VQEG HD3 dataset is relatively smaller.\n\nIt has nine source videos and 72 compressed videos.\n\nAnd these were generated using video coding at 1080p video resolution.\n\nAnd to measure performance of a video quality metric objectively, we make use of correlation and distance measures.\n\nPearson Correlation Coefficient, or PCC in short, measures how well the predicted scores correlate with subjective scores.\n\nA higher PCC value implies better correlation.\n\nAnd RMSE measures how far off the predictions are from subjective scores.\n\nA lower RMSE value would imply higher prediction accuracy.\n\nNow, we want to evaluate how well can AVQT predict the scores given by human subjects.\n\nOn the x-axis here, we have the ground truth subjective video quality scores.\n\nAnd on the y-axis, we have scores predicted by AVQT.\n\nEvery point here represents a compressed video.\n\nAs you can see from the scatter plot, except for a few outliers, AVQT does a great job in predicting the subjective scores for this dataset.\n\nThis is also reflected in the high PCC and low RMSE scores.\n\nAnd we see a high performance on the VQEG HD3 dataset as well.\n\nLet's move on and talk about AVQT's computational speed.\n\nNote that high computational speed is quite important to ensure scalability.\n\nAVQT's algorithm is designed and optimized to run fast on Metal.\n\nThis implies that you can run through large video files very quickly.\n\nIt also takes care of all preprocessing natively.\n\nFor you, this means you don't have to decode your videos and scale them offline.\n\nAVQT does that for you.\n\nYou should note that AVQT runs through a 1080p video at 175 frames per second.\n\nSo if you have a 10-minute long 1080p video at 24 Hz, AVQT can compute its quality in under 1.5 minutes.\n\nThe final attribute we want to talk about is viewing setup awareness.\n\nYour viewing setup can affect the video quality you perceive when watching a video.\n\nIn particular, factors such as display size, display resolution, and viewing distance can mask or exaggerate artifacts in the video.\n\nTo address this, AVQT takes these parameters as input to the tool and then attempts to predict the right trend as these factors change.\n\nLet's take a look at one such case.\n\nConsider two scenarios.\n\nIn scenario A, you're watching a 4K video on a 4K display at a viewing distance of 1.5 times the height of the screen.\n\nIn scenario B, you are watching the same video on the same display but now at a viewing distance which is three times the height of the screen.\n\nClearly, in scenario B you will miss out on some of the artifacts which were visible when you were watching it closely.\n\nThis implies that your perceived video quality in scenario B will be higher than in scenario A.\n\nAnd AVQT can capture such trends at different quality levels.\n\nThe chart here shows that as viewing distance increases from 1.5H to 3H, AVQT scores increase as well.\n\nWe recommend you go over the README document available with the tool for more information on this.\n\nWell, now that we have all of you excited about AVQT, let me show how you can use the tool the right way.\n\nWe will be making AVQT available to all of you soon via the Developer downloads portal.\n\nLet me walk you through a demo.\n\nSo I have already downloaded the tool and installed AVQT on this system.\n\nIf you look at the output of \"which AVQT\", you can see AVQT is placed in the usr/local/bin directory.\n\nNow, you can invoke AVQT help command to read more about the usage of different flags supported by AVQT.\n\nLet's see what I have in my current directory.\n\nI have a sample reference and a sample compressed video that I will use for the demo.\n\nSo let me run AVQT through them.\n\nWe will provide the reference and test files as input and specify an output file.\n\nLet's name the output file sample_output.csv.\n\nThe tool prints the progress and reports the segment scores on the screen.\n\nThe default segment duration is six seconds and since this clip is five seconds long, we have only one segment.\n\nNext, let's look at the output file.\n\nYou can see the frame level scores here.\n\nAnd, finally, we have the segment level scores towards the bottom.\n\nNow, in the demo, we showed a few options, but the tool has several other features built into it as well.\n\nFor example, you can use the segment-duration and the temporal-pooling flags to change the way frame level scores are aggregated.\n\nSimilarly, you can specify the viewing setup using the viewing-distance and display-resolution flags.\n\nPlease refer to the README for more details on this.\n\nAll right.\n\nSo far we have learned about some of the key attributes of AVQT.\n\nWe have also seen how to use the command line tool on a pair of videos to generate video quality scores.\n\nNow let's take a look at a specific case where you can use AVQT to optimize bit rates for HLS.\n\nHLS tiers are encoded at different bit rates.\n\nAnd we know that choosing these bit rates is not an easy process always.\n\nTo help with this, we have published some bit rate guidelines in the HLS Authoring Specification document.\n\nPlease note that these bit rates are only initial encoding targets for typical content delivered via HLS.\n\nWe also know that different content has different encoding complexity, which implies that the optimal bit rate varies across different content.\n\nSo the bit rate that works well for one type of content -- for example, an animation movie -- might not work well for a sporting event.\n\nHere's how you can use AVQT as feedback to help you determine optimal bit rate for your content.\n\nFirst, we start with our initial target bit rates.\n\nWe use this bit rate to encode our source video and create the HLS tier.\n\nWe then use the source video and the encoded HLS tier to compute video quality scores using AVQT.\n\nFinally, we can analyze AVQT scores to decide if we want to increase or decrease the target bit rate for the HLS tier.\n\nTo demonstrate this with an example, let's pick a specific HLS tier.\n\nHere we are choosing the 2160p tier at 11.6 megabits per second.\n\nWe will then encode our previous two sequences -- animation and sports -- with this recommended bit rate.\n\nOnce we have the encoded tiers ready, we will use AVQT to compute their video quality scores.\n\nThe chart here shows AVQT scores for the two video sequences.\n\nFor this particular tier, we can expect a high video quality, so we are setting the threshold to be 4.5, indicating close-to-excellent quality.\n\nYou can see that while this bit rate is good enough for this animation clip, it is not sufficient for the sports clip.\n\nSo we go back and use this feedback to adapt our bit rate target.\n\nIn particular, we need to increase our bit rate target for the sports clip and recompute its AVQT score.\n\nLet's aim for a 10-percent increase in bit rate.\n\nHere we have plotted our new AVQT scores for the sports clip.\n\nThe updated scores now lie above our expected threshold of four and a half.\n\nAnd it also resembles video quality of the animation content much more closely.\n\nTo wrap up, here are a few important things that we want you to take away from this talk.\n\nVideo compression can lead to visible artifacts, which affects consumers' video quality experience.\n\nYou can evaluate the quality of your compressed videos using AVQT.\n\nAVQT comes as a macOS command line tool, is quick to compute, and is viewing setup aware.\n\nIt also has support for all AVFoundation-based video formats.\n\nFinally, you can use AVQT to optimize the video quality of your HLS tiers.\n\nThank you very much! ♪",
    "segments": []
  },
  "resources": {
    "resourceLinks": [
      {
        "title": "Design",
        "url": "https://developer.apple.com/design/"
      },
      {
        "title": "Documentation",
        "url": "https://developer.apple.com/documentation/"
      },
      {
        "title": "Forums",
        "url": "https://developer.apple.com/forums/"
      },
      {
        "title": "Apple Design Awards",
        "url": "https://developer.apple.com/design/awards/"
      }
    ],
    "hdVideo": "https://devstreaming-cdn.apple.com/videos/wwdc/2021/10145/4/FFBDCD0F-8B65-4D91-A05A-1501F7494854/downloads/wwdc2021-10145_hd.mp4?dl=1",
    "sdVideo": "https://devstreaming-cdn.apple.com/videos/wwdc/2021/10145/4/FFBDCD0F-8B65-4D91-A05A-1501F7494854/downloads/wwdc2021-10145_sd.mp4?dl=1"
  },
  "relatedVideos": [
    {
      "id": "10149",
      "year": "2022",
      "title": "What’s new in AVQT",
      "url": "https://developer.apple.com/videos/play/wwdc2022/10149"
    }
  ],
  "extractedAt": "2025-07-18T09:24:10.177Z"
}