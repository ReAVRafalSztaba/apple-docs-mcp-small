{
  "id": "10073",
  "year": "2023",
  "url": "https://developer.apple.com/videos/play/wwdc2023/10073/",
  "title": "Design for spatial input",
  "speakers": [],
  "duration": "",
  "topics": [
    "Design"
  ],
  "hasTranscript": true,
  "hasCode": false,
  "transcript": {
    "fullText": "♪ Mellow instrumental hip-hop ♪ ♪ Israel Pastrana Vicente: Hello and welcome to \"Design for Spatial Input.\" My name is Israel, and I'm here with Eugene.\n\nWe are designers on the Apple Design team.\n\nEugene Krivoruchko: Today, we'll talk about designing interactions for eyes and hands.\n\nWe'll cover what's special about these new input methods, and how to make the best use of them on our platform.\n\nIsrael: Let's take a quick look at all the available input modalities.\n\nWith spatial input, you can simply look at a button and tap your fingers together to select it, keeping your arm relaxed on your lap.\n\nOur system is designed to interact with UI comfortably at a distance.\n\nIn some cases, you can also interact with elements directly.\n\nFor example, typing on a virtual keyboard using your fingertips.\n\nHolding your hands in the air can cause fatigue, but we will see that some tasks are better suited to interact directly.\n\nNow, eyes and hands are the new spatial inputs, but you can also use other familiar inputs like voice to search without needing to type.\n\nOr keyboard and trackpad, which are great for getting things done.\n\nLastly, you can also connect a game controller to play your favorite games.\n\nWe are going to focus on the most new and exciting spatial inputs: eyes and hands.\n\nUsing your eyes and hands to interact is distinct in a few ways.\n\nFirst, it's personal.\n\nYour eye movements and hand gestures are unique to you.\n\nAn array of cameras inside and outside the device capture all the details of your natural movements in a privacy-respectful way.\n\nNext, it's comfortable.\n\nYou can keep your hands resting beside you because the device sees a wide area around you.\n\nLastly, it makes spatial interactions precise.\n\nThe device filters all the data and translates it into accurate interactions that you can use in your apps.\n\nSo spatial input, it's a personal input that feels incredibly comfortable while providing you great precision to control your interactions.\n\nToday, we'll be going over how to use your eyes and hands to interact naturally with your apps.\n\nLet's start with eyes.\n\nEyes are the primary targeting mechanism for spatial experiences.\n\nAll the interfaces in the system react to where you look.\n\nAnd we can effortlessly target any element just by looking at them, no matter how far away they are.\n\nNow, I'll talk about how to make apps that are comfortable to interact with; how to make them easy to target with your eyes; how to make interfaces that respond to where you look while respecting privacy; and finally, how eye intent simplifies our layouts and offers unique assistive options.\n\nIn order to build apps that are comfortable for the eyes, we need to consider how your content shows up in the device.\n\nHere's the first thing to consider.\n\nEven though you have an infinite canvas for your apps, you only see the content inside the field of view.\n\nWithin the field of view, it's most comfortable to look in the center, and it's less comfortable to look at the edges.\n\nSo, design apps that fit inside the field of view, minimizing neck and body movement.\n\nTry to keep the main content of the app in the center of the field of view, the most comfortable area for your eyes.\n\nLooking at the edges of the field of view can be tiring for your eyes, so use these areas for content that you don't need all the time, like secondary actions, which remain accessible and don't interfere with the main content.\n\nAlways try to maximize eye and neck comfort in your apps by placing the content inside the field of view.\n\nNow, we should also consider depth when thinking about eye comfort.\n\nDepth is a unique feature of spatial experiences.\n\nPlacing your content near or far away creates different feelings in your projects.\n\nBut our eyes focus on one distance at a time, and changing the focus depth frequently can create eye strain.\n\nLook to keep interactive content at the same depth to make it feel effortless to switch between UI.\n\nFor example, presenting a modal view pushes the main view in the z-axis, and the modal is placed at the original distance.\n\nBy maintaining the same Z position, your eyes don't need to adapt to the new distance.\n\nNow, you can use subtle changes in depth to communicate hierarchy, like in this example, with a tab bar on the left and a segmented control at the bottom.\n\nThis way, you're using depth meaningfully, while avoiding eye discomfort.\n\nNow that we've seen how to make an app comfortable, we also need to make it easy to use with your eyes.\n\nEyes are very precise, but there are certain qualities that help our eyes target successfully on UI elements.\n\nOur eyes naturally focus on shapes that guide our attention to the middle of an object.\n\nTo help our eyes, use round shapes like circles, pills, and rounded rectangles.\n\nAvoid using shapes with sharp edges.\n\nWhen you use sharp edges, your eyes tend to focus on the outside, decreasing eye precision.\n\nAlso, keep the shapes flat and avoid thick outlines or effects that call attention to the edges.\n\nAnd lastly, make sure to center the text and the glyphs in your elements using generous padding.\n\nSo, always make sure that your UI is designed to guide the eyes to the center of the element.\n\nNow that our attention is in the middle of our elements, let's look at the right size for your controls.\n\nThe minimum area that your element needs for eye target is 60 points.\n\nBut the element can be smaller than 60 points.\n\nYou can achieve the minimum target area combining size and spacing.\n\nUse generous spacing between elements in your layouts.\n\nThis will help you target quickly and accurately with your eyes.\n\nAgain, it's very important to respect the minimum target area of 60 points, combining size and spacing to make your UI look great and easy to use with your eyes.\n\nOut of the box, standard components have sizes that are easy to target.\n\nUse these components as much as you can.\n\nAnd if you use your own, make sure to follow our guidelines on sizing.\n\nTo learn more about points and layout, check out the session \"Design for spatial user interfaces.\" Now that we've learned about how important the target area is for your eyes, we have to make sure that we maintain this target area in any position in a space.\n\nFor that, we need to understand how to scale your UI.\n\nLet's look at two different scale mechanisms.\n\nThe system provides dynamic scale for app windows.\n\nYou can see how the window scales larger as it moves away, and smaller as it moves close.\n\nDynamic scale makes your UI fill the same field of view and preserve the size of the target areas, no matter where the window is positioned.\n\nIf you use fixed scale instead, your UI becomes smaller as it moves away.\n\nFixed scale changes the size of the interface and makes your app difficult to use with your eyes.\n\nLet's look at this side by side.\n\nDynamic scale keeps your UI and the target areas at the same size, while fixed scale changes the size and makes the target areas too small.\n\nWhen you create custom UI, use dynamic scale to ensure that your eyes can always target all the controls.\n\nBesides scale, orientation also affects the usability of your app.\n\nIf the interface is at an angle, it's difficult to read and hard to use.\n\nThat's why system windows are always oriented to face people.\n\nBut if you create custom windows in your app, always make sure to keep your UI facing the viewer.\n\nAs we've just seen, correct scale and orientation of windows and UI are fundamental to ensure accuracy with your eyes.\n\nTo learn more about how windows on this platform behave, check out the session \"Principles of spatial design.\" Eyes are a very novel input. and it's really important to make your interfaces respond to your eyes.\n\nWhen interactive elements highlight, you understand that your eyes are driving the interaction.\n\nLet's see what happens when you look at a group of buttons.\n\nSee how they highlight as you look at each one.\n\nAll interactive elements should be highlighted, and we do this with a hover effect.\n\nBut because your eyes move quickly, the effect needs to be subtle and work on top of any content, like when looking at your favorite photos, reinforcing intention without being prominent.\n\nThanks to the hover effect, all the system-provided controls highlight when you look at them.\n\nIf you create custom elements for your apps, use hover effects to add eye feedback and make your elements feel responsive.\n\nNow, eye intention is very sensitive information.\n\nPrivacy is our top priority when dealing with eye data.\n\nThe hover effect happens out of your app's process, so you will only get the information of which element is focused when there is an interaction on the element triggered by a gesture.\n\nHovering on an element with your eyes is a signal for intention.\n\nWhen you look at something for a long time, we know that you are interested in it.\n\nIt is a great opportunity to show you more information about it.\n\nFor example, buttons can have tooltips that reveal as you look at them.\n\nAlso, tab bars expand when you focus on them, showing a label for each tab.\n\nLastly, focusing on the microphone glyph inside a system-provided search field will trigger Speak to Search, revealing this layer and allowing you to perform a search using just eyes and voice.\n\nAll these system elements give extra information when you need it, while keeping a clean UI when not in focus.\n\nTake advantage of them when creating your apps.\n\nThey are also built with privacy in mind to ensure that no focus information is being sent to the app.\n\nEye intent also provides great opportunities for assistive technology.\n\nFor example, using the Dwell Control feature, you can select content just with your eyes.\n\nIn this example, focusing on a button for a short time will show the Dwell Control UI and will select the button without needing to perform a tap gesture with your hand.\n\nSo, what did we just learn about designing interactions for eyes? We learned about how to make your apps comfortable for your eyes by placing content in front of the viewer, inside the field of view, and using depth responsibly.\n\nThen we looked at how to design interfaces that are easy to use and how to guide your eyes to the center of the elements.\n\nWe also reinforced how important it is to respect the minimum target area of 60 points in your controls.\n\nHow we should always communicate interactivity and reinforce targeting by adding hover effects to your elements.\n\nAnd lastly, how we can take advantage of UI elements that reveal extra information on eye intent.\n\nI think this was great, and there's even more.\n\nWe've seen that eyes are a fantastic target mechanism, and they become much more powerful when you combine them with hands.\n\nNow, I'll hand it over to Eugene to talk about it.\n\nEugene: Thanks, Israel.\n\nLet's talk about hands.\n\nCombined with eyes for targeting, hand gestures are the primary way to interact across the system.\n\nPinching your fingers together is an equivalent of pressing on the screen of your phone.\n\nThe system supports other familiar gestures.\n\nFor example, you can pinch and drag to scroll, and perform two-handed gestures like zoom and rotate.\n\nNotice how in all these cases, UI feedback continues the motion of the hand, which really helps it feel connected to the gesture.\n\nThe gestures work the same way across the system and follow the logic similar to the Multi-Touch gestures.\n\nThis means that people can really focus on the experience, instead of having to think about how to perform the interaction.\n\nThis is why you should lean on these familiar patterns when designing your experience, and make sure to respond to gestures in a way that matches people's expectations.\n\nIn some cases, part of your experience might be a unique behavior that can't easily be expressed with standard gestures.\n\nIn this case, you may want to define a custom one.\n\nHere are some tips on how to make a successful custom gesture.\n\nFirst, make sure that the gesture is easy to explain and perform so that people can learn how to use it quickly.\n\nIt is also important to avoid gesture conflicts.\n\nYour custom gesture needs to be distinctly different from the standard system set or common hand movements people might use in the conversation.\n\nThis has to be a gesture that people can consistently repeat without strain or fatigue, and that has a low rate of false activations.\n\nBe mindful of people who are using assistive technologies to interact across the system and consider how your gesture will work in those cases.\n\nTo learn more about accessibility, check out the session \"Create accessible spatial experiences.\" Gestures can also mean different things to different people, so make sure your custom gesture doesn't send messages you didn't intend.\n\nAll of this may be a tricky balance to hit, so it's always worth considering a fallback in the form of a UI affordance.\n\nOne of the most exciting aspects of our input model is the opportunity to use eyes as a signal of intent.\n\nUsing eye direction combined with hand gestures, we can create precise and satisfying interactions that are not possible on other platforms.\n\nLet's look at the zoom gesture again to see what I mean.\n\nAt the start of the gesture, the origin point of the zoom is determined by where within the image your eyes are focused at that moment.\n\nThis results in that particular area to be magnified and centered as you zoom in.\n\nAs a result, you can navigate the image easily just by looking around and performing this simple gesture.\n\nThis feels really magical and 100 percent expected at the same time.\n\nThe point you are looking at naturally indicates the intent of that interaction.\n\nAnother example of this behavior is pointer movement in Markup.\n\nTo draw, you control the brush cursor with your hand, similar to a mouse pointer, but then if you look to the other side of the canvas and tap, the cursor jumps there landing right where you're looking.\n\nThis creates a sense of accuracy and helps to cover the large canvas quickly.\n\nThese are examples of interactions that use eye direction to make simple behaviors more precise and satisfying.\n\nEyes are used not only to target elements, but to implicitly provide a more granular location for that interaction.\n\nThis is a really powerful aspect of our input model that allows us to respond to interaction in a much more intelligent way.\n\nNow let's talk about direct touch.\n\nAcross the system, we support being able to reach out and use your fingertips to interact.\n\nFor example, you can bring Safari close to you and scroll the page directly.\n\nYou can also use both your hands to type on the virtual keyboard and even have more spatial experiences, manipulating 3D content within your arm's reach.\n\nInteractions at a distance stay comfortable for a long time because it's easy to target controls with your eyes, and your hands can stay rested while performing minimal gestures.\n\nWhen designing for direct interaction, we have to keep in mind that holding hands in the air will cause fatigue after a while.\n\nStill, certain apps will benefit from placing content within arm's reach for direct touch, like experiences that invite up close inspection or object manipulation; or any interactive mechanic that builds on top of the muscle memory from real-world experiences; and generally, whenever physical activity is at the center of the experience.\n\nLack of tactile response is another thing to consider when designing for direct interaction.\n\nEvery time we touch something in the physical world, our hands receive lots of multisensory feedback, which is essential to our perception.\n\nNone of this is happening when we reach out and touch virtual content.\n\nAnd to make that interaction work, we need to compensate for the missing sensory information with other types of feedback.\n\nLet's look at how we approached this challenge with keyboard buttons.\n\nThe buttons are actually raised above the platter to invite pushing them directly.\n\nWhile the finger is above the keyboard, buttons display a hover state and a highlight that gets brighter as you approach the button surface.\n\nIt provides a proximity cue and helps guide the finger to target.\n\nAt the moment of contact, the state change is quick and responsive, and is accompanied by matching spatial sound effect.\n\nThese additional layers of feedback are really important to compensate for missing tactile information, and to make direct interactions feel reliable and satisfying.\n\nAudio plays a special role in connecting input with virtual content across the system.\n\nTo learn more about it, check out the session called \"Explore immersive sound design.\" To recap, here are the takeaways for designing interactions with hands.\n\nUse gesture language consistent with the system so people can focus on the content instead of the interaction.\n\nBe careful to only introduce custom gestures when the desired behavior can't be achieved with the standard set.\n\nLook for ways to improve your interaction using eyes as a signal of intent.\n\nOnly use direct interaction when it's at the core of your experience.\n\nAnd if you do, provide extensive feedback to compensate for missing sensory information.\n\nToday, we have talked about some of the design principles for spatial interactions with eyes and hands.\n\nWe talked a lot about comfort and ergonomics.\n\nWith so many ways for how software can look, behave, and react to input on this platform, there is more responsibility on designers and developers to make sure these experiences are comfortable and accessible.\n\nBy running your app on device, people welcome your work into their space and give it their full attention.\n\nSoftware is no longer contained within a screen.\n\nInstead, it's allowed to occupy a more significant portion of people's physical surroundings and react to their natural body movements.\n\nUsing hands to interact with virtual content is also something very new for most people.\n\nThat's why it's so important to guide them by providing clear feedback and to rely on familiar interaction patterns where possible.\n\nAs we know from designing for other platforms, great input experience is the one that you don't have to think about.\n\nSoftware response becomes a natural continuation of your body movement and perfectly matches the interaction intent.\n\nOur ability to use eyes as the foundation of the input model opens up opportunities to respond to interaction with magical precision.\n\nWe think it's really powerful, and we hope you will use it to create delightful and novel interactions for the spatial medium.\n\nPlease make sure to check out the sessions that we have referenced throughout the talk.\n\nThanks for watching! Israel: Adios! ♪",
    "segments": []
  },
  "resources": {
    "resourceLinks": [
      {
        "title": "Design",
        "url": "https://developer.apple.com/design/"
      },
      {
        "title": "Documentation",
        "url": "https://developer.apple.com/documentation/"
      },
      {
        "title": "Forums",
        "url": "https://developer.apple.com/forums/"
      },
      {
        "title": "Apple Design Awards",
        "url": "https://developer.apple.com/design/awards/"
      }
    ],
    "hdVideo": "https://devstreaming-cdn.apple.com/videos/wwdc/2023/10073/4/0B0E3324-4B02-4EF4-8413-13A63715B2C5/downloads/wwdc2023-10073_hd.mp4?dl=1",
    "sdVideo": "https://devstreaming-cdn.apple.com/videos/wwdc/2023/10073/4/0B0E3324-4B02-4EF4-8413-13A63715B2C5/downloads/wwdc2023-10073_sd.mp4?dl=1"
  },
  "relatedVideos": [
    {
      "id": "10078",
      "year": "2023",
      "title": "Design considerations for vision and motion",
      "url": "https://developer.apple.com/videos/play/wwdc2023/10078"
    },
    {
      "id": "10076",
      "year": "2023",
      "title": "Design for spatial user interfaces",
      "url": "https://developer.apple.com/videos/play/wwdc2023/10076"
    },
    {
      "id": "10075",
      "year": "2023",
      "title": "Design spatial SharePlay experiences",
      "url": "https://developer.apple.com/videos/play/wwdc2023/10075"
    },
    {
      "id": "10271",
      "year": "2023",
      "title": "Explore immersive sound design",
      "url": "https://developer.apple.com/videos/play/wwdc2023/10271"
    },
    {
      "id": "10072",
      "year": "2023",
      "title": "Principles of spatial design",
      "url": "https://developer.apple.com/videos/play/wwdc2023/10072"
    }
  ],
  "extractedAt": "2025-07-18T09:36:14.698Z"
}