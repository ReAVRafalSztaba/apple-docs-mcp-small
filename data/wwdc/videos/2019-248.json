{
  "id": "248",
  "year": "2019",
  "url": "https://developer.apple.com/videos/play/wwdc2019/248/",
  "title": "Creating an Accessible Reading Experience",
  "speakers": [],
  "duration": "",
  "topics": [
    "Accessibility & Inclusion"
  ],
  "hasTranscript": true,
  "hasCode": false,
  "transcript": {
    "fullText": "Hello. Welcome to Creating a Great Accessible Reading Experience. My name is Darren Minifie, and I'm an engineering manager on the Accessibility Team.\n\nThe hallmark for a great application is an outstanding user interface. This extends to the layout and styling of text especially for apps whose primary focus is the presentation of long form readable content.\n\nTo implement a custom text layout you often need to turn to lower level technologies such as Core Text and TextKit.\n\nIn this session, you will learn the APIs and techniques you need to create an equally great accessible reading experience for VoiceOver.\n\nWe'll begin by talking about the reading content protocol. You use this protocol to make your text content accessible. Next, we'll talk about automatic page turning, which VoiceOver uses to turn the pages in your application. Finally, we'll discuss the APIs you can use to customize the way VoiceOver speaks your content.\n\nIn the session, we'll use the following sample app to demonstrate these techniques.\n\nThe app is a simple page-based application where each page consists of an image, a title, a subtitle and some detail text.\n\nTo make your app accessible, you should first audit it with VoiceOver. A convenient way to do this is to add VoiceOver to your accessibility shortcut. You can do this by launching settings, tapping accessibility, scrolling down to accessibility shortcut and tapping VoiceOver. Now depending on your hardware, you can press the home button or side button 3 times to quickly enable and disable VoiceOver.\n\nLet's see how VoiceOver interacts with the sample app. VoiceOver on.  As I drag my finger across the screen, VoiceOver plays a sound effect indicating there is no content to be found. Therefore, the first thing we need to do is make our text content accessible.\n\nTo make your content accessible, you should use the UIAccessibilityReadingContent Protocol. This protocol consists of 4 core methods.\n\nAccessibilityLineNumber(for point asks you to return the line number for a given touch location. AccessibilityContent (forLineNumber and accessibilityFrame (forLineNumber asks for the text content and rect for a given line respectively.\n\nFinally, accessibilityPageContent asks you to return the entire pages worth of content.\n\nLet's see how we would implement the UIAccessibilityReadingContent Protocol in our sample app.\n\nEach page in the sample app is represented by an instance of SessionItemView.\n\nThis view has 4 sub views; an image view, a title label, an identifier label and a session details view.\n\nWe additionally declare a layout enum. This will help us in our method implementations that follow.\n\nThe first thing we need to do is make our page view an accessibility element. We do this by setting isAccessibilityElement to true in the page views initializer.\n\nNext, we begin to implement the reading content protocol. Our first method is accessibilityLineNumber(for point.\n\nFirst, we hitTest the page view using the past in line number.\n\nIf the resulting view is one of our known sub views, we map that to the value of our layout enum. Finally, we return the rawValue as this is the representation VoiceOver understands.\n\nNext to implement AccessibilityContent (forLineNumber, we begin by instantiating an instance of the layout enum. We switch over the possible cases and map that to one of our known sub views. Finally, we return accessibility label, which returns the text for that sub view.\n\nThe implementation of accessibilityFrame (forLineNumber is very similar. We begin by creating a new instance of the layout enum with our given raw value. We switch over the possible cases and map that to one of our known sub views. Finally, we return accessibility frame, which represents the rect for a given line.\n\nFinally, to implement accessibilityPageContent we gather together the text from our known sub views and return them as a single string.\n\nLet's see how the app interacts with VoiceOver with the reading content protocol implemented.\n\nAccessible drag-and-drop. Session 241. Drag-and-drop is a powerful API that allows apps to share and communicate data. This time as I drag my finger across the screen VoiceOver speaks and highlights the corresponding text.\n\nNext let's talk about automatic page turning. When VoiceOver's read all command is invoked, it's expected that VoiceOver will be able to read all of your content from beginning to end. This may require VoiceOver to turn pages in your app. To implement automatic page turning you need to adopt 2 accessibility APIs. First, you should include the causesPageTurn accessibility trait on your page view. Second, you should implement AccessibilityScroll in direction. This gives VoiceOver the ability to turn pages in your app.\n\nLet's see how we would implement automatic page turning in our sample app.\n\nFirst, we need to include the causesPageTurn accessibility trait. We do this by setting accessibility trait in the page views initializer.\n\nNext, we implement accessibilityScroll and direction. We do this by switching over the possible cases of the direction parameter. If the direction is previous or left, we ask our delegate to turn to the previous page. If that's successful, we notify VoiceOver with a pageScrolled notification.\n\nSimilarly, if the value is right or next, we ask the delegate to turn to the next page and if that's successful, we notify VoiceOver with a pageScrolled notification.\n\nLet's see how the app interacts with automatic page turning implemented.\n\nAccessible drag-and-drop Session 241. Drag-and-drop is a powerful API that allows apps to share and communicate data. No matter how you decide to implant drag-and-drop there's a way to make it work for people with accessibility needs. Learn the details as we dive into accessible drag-and-drop for iOS.\n\nAVSpeechSynthesizer. Making iOS talk. Session 236. Our final topic is customizing speech. You may want to control the way VoiceOver speaks your app's content. To do this you can use 2 alternate methods in the reading content protocol. These method versions return NSAttributedStrings instead of simple strings. By supplying the appropriate accessibility attributes, you can control various aspects about how VoiceOver speaks your content.\n\nFor example, you may have a passage you would like spoken in a particular language. To do this you can include the accessibilitySpeechLanguage attribute along with the appropriate language identifier. This causes VoiceOver to use the most appropriate voice to speak your content. Arc de Triomphe.\n\nFurthermore, you may want fine-grained control over the way VoiceOver speaks your content. To do this you can supply the IPA representation for your passage along with the accessibilitySpeechIPANotation attribute.\n\nYosemite National Park.\n\nSo to create a great reading experience for VoiceOver, you first need to make your text content accessible. You do this by implementing the UIAccessibilityReadingContent protocol. Next, you should implement automatic page turning so VoiceOver can read all of the content in your app from beginning to end. Finally, to control the way VoiceOver speaks your content, you should consider using the NS attributed strings versions of the methods in the reading content protocol and supply the appropriate accessibility attributes.\n\nFor more information about this topic, please visit the following session URL.\n\nThanks for watching.",
    "segments": []
  },
  "resources": {
    "resourceLinks": [
      {
        "title": "Design",
        "url": "https://developer.apple.com/design/"
      },
      {
        "title": "Documentation",
        "url": "https://developer.apple.com/documentation/"
      },
      {
        "title": "Forums",
        "url": "https://developer.apple.com/forums/"
      },
      {
        "title": "Apple Design Awards",
        "url": "https://developer.apple.com/design/awards/"
      }
    ],
    "hdVideo": "https://devstreaming-cdn.apple.com/videos/wwdc/2019/248ts94v3ev4q5/248/248_hd_creating_an_accessible_reading_experience.mp4?dl=1",
    "sdVideo": "https://devstreaming-cdn.apple.com/videos/wwdc/2019/248ts94v3ev4q5/248/248_sd_creating_an_accessible_reading_experience.mp4?dl=1"
  },
  "relatedVideos": [
    {
      "id": "10022",
      "year": "2020",
      "title": "Create a seamless speech experience in your apps",
      "url": "https://developer.apple.com/videos/play/wwdc2020/10022"
    }
  ],
  "extractedAt": "2025-07-18T09:09:39.852Z"
}