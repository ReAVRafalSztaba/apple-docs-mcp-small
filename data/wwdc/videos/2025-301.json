{
  "id": "301",
  "year": "2025",
  "url": "https://developer.apple.com/videos/play/wwdc2025/301/",
  "title": "Deep dive into the Foundation Models framework",
  "speakers": [],
  "duration": "",
  "topics": [
    "Machine Learning & AI"
  ],
  "hasTranscript": true,
  "hasCode": true,
  "transcript": {
    "fullText": "Hi, I’m Louis. Today we’ll look at getting the most out of the Foundation Models framework.\n\nAs you may know, the Foundation Models framework gives you direct access to an on-device Large Language Model, with a convenient Swift API. It’s available on macOS, iPadOS, iOS, and visionOS. And because it runs on-device, using it in your project is just a simple import away. In this video, we will look at how sessions work with Foundation Models. How to use Generable to get structured output. How to get structured output with dynamic schemas defined at runtime, and using tool calling to let the model call into your custom functions.\n\nLet’s start simple, by generating text with a session.\n\nNow, I’ve been working on this pixel art game about a coffee shop, and I think it could be really fun to use Foundation Models to generate game dialog and other content to make it feel more alive! We can prompt the model to respond to a player’s question, so our barista gives a unique dialog.\n\nTo do this, we’ll create a LanguageModelSession with custom instructions. This let’s us tell the model what its purpose is for this session and for the prompt we’ll take the user’s input. And that’s really all it takes for a pretty fun new game element. Let’s ask the Barista “How long have you worked here?”, and let it respond to our question.\n\nThat was generated entirely on-device. Pretty amazing. But how does this actually work? Let’s get a better sense of how Foundation Models generates text, and what to look out for. When you call respond(to:) on a session, it first takes your session’s instructions, and the prompt, in this case the user’s input, and it turns that text into tokens. Tokens are small substrings, sometimes a word but typically just a few characters. A large language model takes a sequence of tokens as input, and it then generates a new sequence of tokens as output. You don’t have to worry about the exact tokens that Foundation Models operates with, the API nicely abstracts that away for you. But it is important to understand that tokens are not free. Each token in your instructions and prompt adds extra latency. Before the model can start producing response tokens, it first needs to process all the input tokens. And generating tokens also has a computational cost, which is why longer outputs take longer to generate.\n\nA LanguageModelSession is stateful. Each respond(to:) call is recorded in the transcript.\n\nThe transcript includes all prompts and responses for a given session.\n\nThis can be useful for debugging, or even showing it in your UI.\n\nBut a session has a limit for how large it can grow.\n\nIf you’re making a lot of requests, or if you’re giving a large prompt or getting large outputs, you can hit the context limit.\n\nIf your session exceeds the available context size, it will throw an error, which you should be prepared to catch.\n\nBack in our game, when we’re talking with a character and hit an error, the conversation just ends, which is unfortunate, I was just getting to know this character! Luckily there are ways to recover from this error.\n\nYou can catch the exceededContextWindowSize error.\n\nAnd when you do, you can start a brand new session, without any history. But in my game that would mean the character suddenly forgets the whole conversation.\n\nYou can also choose some of the transcript from your current session to carry over into the new session.\n\nYou can take the entries from a session’s transcript, and condense it into a new array of entries.\n\nSo for our game dialog, we could take the first entry of the session’s transcript, which is the instructions. As well as the last entry, which is the last successful response.\n\nAnd when we pass that into a new session, our character is good to chat with for another while.\n\nBut keep in mind, the session’s transcript includes the initial instructions as the first entry. When carrying over a transcript for our game character, we definitely want to include those instructions.\n\nIncluding just a few relevant pieces from the transcript can be a simple, and effective, solution. But sometimes it’s not that simple.\n\nLet’s imagine a transcript with more entries.\n\nYou definitely always want to start by carrying over the instructions. But a lot of entries in the transcript might be relevant, so for this use case you could consider summarizing the transcript.\n\nYou could do this with some external library, or perhaps even summarize parts of the transcript with Foundation Models itself.\n\nSo that’s what you can do with the transcript of a session.\n\nNow let’s take a brief look at how the responses are actually generated.\n\nIn our game, when you walk up to the barista, the player can ask any question.\n\nBut if you start two new games, and ask the exact same question in each, you will probably get different output. So how does that work? Well that’s where sampling comes in.\n\nWhen the model is generating its output, it does so one token at a time. And it does this by creating a distribution, for the likelihood of any given token By default, Foundation Models will pick tokens within some probability range. Sometimes it might start by saying “Ah”, and other times it might pick “Well” for the first token. This happens for every token that’s generated. Picking a token is what we call sampling. And the default behavior is random sampling. Getting varied output is great for use cases like a game. But sometimes you might want deterministic output, like when you’re writing a demo that should be repeatable. The GenerationOptions API let’s you control the sampling method. You can set it to greedy to get deterministic output. And when that’s set, you will get the same output for the same prompt, assuming your session is also in the same state. Although note, this only holds true for a given version of the on-device model. When the model is updated as part of an OS update, your prompt can definitely give different output, even when using greedy sampling.\n\nYou can also play with the temperature for the random sampling. For example, setting the temperature to 0.5 to get output that only varies a little. Or setting it to a higher value to get wildly different output for the same prompt.\n\nAlso, keep in mind, when taking user input in your prompt, the language might not be supported.\n\nThere is the dedicated unsupportedLanguageOrLocale error that you can catch for this case.\n\nThis can be a good way to show a custom message in your UI.\n\nAnd there’s also an API to check whether the model supports a certain language. For example to checkout if the user’s current language is supported, and to show a disclaimer when it’s not. So that’s an overview of sessions. You can prompt it, which will store the history in the transcript. And you can optionally set the sampling parameter, to control the randomness of the session’s output. But let’s get fancier! When the player walks around, we can generate NPCs, Non Playable Characters, again using Foundation Models. However, this time, we want more complicated output. Instead of just plain text, we’d like a name and a coffee order from the NPC. Generable can help us here.\n\nIt can be a challenge to get structured output from a Large Language Model. You could prompt it with the specific fields you expect, and have some parsing code to extract that. But this is hard to maintain, and very fragile, it might not always give the valid keys, which would make the whole method fail.\n\nLuckily, Foundation Models has a much better API, called Generable.\n\nOn your struct, you can apply the @Generable macro. So, what is Generable and is that even a word? Well, yes, it is.\n\nGenerable is an easy way to let the model generate structured data, using Swift types The macro generates a schema at compile time, which the model can use to produce the expected structure.\n\nThe macro also generates an initializer, which is automatically called for you when making a request to a session.\n\nSo then we can generate instances of our struct. Like before, we’ll call the respond method on our session. But this time pass the generating argument telling the model which type to generate.\n\nFoundation Models will even automatically include details about your Generable type in the prompt, in a specific format that the model has been trained on. You don’t have to tell it about what fields your Generable type has In our game, we’ll now get some great generated NPC encounters! Generable is actually more powerful than it might seem. At a low level, this uses constrained decoding, which is a technique to let the model generate text that follows a specific schema.\n\nRemember, that schema that the macro generates.\n\nAs we saw before, an LLM generates tokens, which are later transformed into text. And with Generable, that text is even automatically parsed for you in a type-safe way. The tokens are generated in a loop, often referred to as the decoding loop.\n\nWithout constrained decoding, the model might hallucinate some invalid field name.\n\nLike `firstName`instead of a name. Which would then fail to be parsed into the NPC type.\n\nBut with constrained decoding, the model is prevented from making structural mistakes like this. For every token that’s generated, there’s a distribution of all the tokens in the model’s vocabulary.\n\nAnd constrained decoding works by masking out the tokens that are not valid. So instead of just picking any token, the model is only allowed to pick valid tokens according to the schema.\n\nAnd that’s all without needing to worry about manually parsing the model’s output. Which means you can spend your time on what truly matters, like talking to virtual guests in your coffee shop! Generable is truly the best way to get output from the on-device LLM. And it can do so much more. Not only can you use it on structs, but also on enums! So let’s use that to make our encounters more dynamic! Here, I’ve added an Encounter enum, with two cases. The enum can even contain associated values in its cases, so let’s use that to either generate a coffee order, or, to have someone that wants to speak to the manager.\n\nLet’s checkout what we encounter in our game now! Wow, someone really needs a coffee.\n\nClearly, not every guest is as easy to deal with, so let’s level this up by adding levels to our NPCs.\n\nGenerable supports most common Swift types out of the box, including Int. So let’s add a level property. But we don’t want to generate any integer. If we want the level to be in a specific range, we can specify this using a Guide. We can use the Guide macro on our property, and pass a range.\n\nAgain, the model will use constrained decoding, to guarantee a value in this range.\n\nWhile we’re at it, let’s also add an array of attributes to our NPC.\n\nWe can again use a guide, this time to specify we want exactly three attributes for this array in our NPC. Keep in mind, the properties of your Generable type are generated in the order they are declared in the source code. Here, name will be generated first, followed by the level, then the attributes, and encounter last.\n\nThis order can be important, if you’re expecting the value of a property to be influenced by another property.\n\nAnd you can even stream property-by-property, if you don’t want to wait until the full output is generated. The game is pretty fun now! Almost ready to share with my friends. But I notice the names of the NPCs aren’t exactly what I had in mind. I would prefer to have a first and last name.\n\nWe can use a guide for this, but this time just provide a natural language description.\n\nWe can say our name should be a “full name”.\n\nAnd this is effectively another way of prompting. Instead of having to describe different properties in your prompt, you can do it directly in your Generable type. And it gives the model a stronger relation for what these descriptions are tied to.\n\nIf we walk around in our game now, we’ll checkout these new names in action.\n\nHere’s an overview of all the guides you can apply to different types.\n\nWith common numerical types, like int, you can specify the minimum, maximum or a range. And with array, you can control the count, or specify guides on the array’s element type.\n\nFor String, you can let the model pick from an array with anyOf, or even constrain to a regex pattern.\n\nA regex pattern guide is especially powerful. You may be familiar with using a regex for matching against text. But with Foundation Models, you can use a regex pattern to define the structure of a string to generate. For example, you can constrain the name to a set of prefixes.\n\nAnd you can even use the regex builder syntax! If this renews your excitement in regex, make sure to watch the timeless classic “Meet Swift Regex” from a few years ago.\n\nTo recap, Generable is a macro that you can apply to structs and enums, and it gives you a reliable way to get structured output from the model. You don’t need to worry about any of the parsing, and to get even more specific output, you can apply guides to your properties.\n\nSo Generable is great when you know the structure at compile time.\n\nThe macro generates the schema for you, and you get an instance of your type as output. But sometimes you only know about a structure at runtime. That’s where dynamic schemas can help.\n\nI’m adding a level creator to my game, where players can dynamically define entities to encounter while walking around in the game. For example, a player could create a riddle structure. Where a riddle has a question, and multiple choice answers. If we knew this structure at compile time, we could simply define a Generable struct for it. But our level creator allows for creating any structure the player can think of.\n\nWe can use DynamicGenerationSchema to create a schema at runtime.\n\nJust like a compile-time defined struct, a dynamic schema has a list of properties. We can add a level creator, that can take a player’s input.\n\nEach property has a name and its own schema, which defines its type. You can use the schema for any Generable type, including built-in types, such as String.\n\nA dynamic schema can contain an array, where you then specify a schema for the element of the array. And importantly, a dynamic schema can have references to other dynamic schemas.\n\nSo here, our array can reference a custom schema that is also defined at runtime.\n\nFrom the user’s input, we can create a riddle schema, with two properties.\n\nThe first is the question, which is a string property. And secondly, an array property, of a custom type called Answer.\n\nAnd we'll then create the answer. This has a string and boolean property.\n\nNote that the riddle’s answers property refers to the answer schema by its name.\n\nThen we can create the DynamicGenerationSchema instances. Each dynamic schema is independent. Meaning the riddle dynamic schema doesn't actually contain the answer’s dynamic schema. Before we can do inference, we first have to convert our dynamic schemas into a validated schema. This can throw errors if there are inconsistencies in the dynamic schemas, such as type references that don’t exist.\n\nAnd once we have a validated schema, we can prompt a session as usual. But this time, the output type is a GeneratedContent instance. Which holds the dynamic values.\n\nYou can query this with the property names from your dynamic schemas. Again, Foundation Models will use guided generation to make sure the output matches your schema. It will never make up an unexpected field! So even though it’s dynamic, you still don’t have to worry about manually parsing the output.\n\nSo now when the player encounters an NPC, the model can generate this dynamic content. Which we’ll show in a dynamic UI. Let’s checkout what we run into. I’m dark or light, bitter or sweet, I wake you up and bring the heat, what am I? Coffee or hot chocolate. I think the answer is coffee.\n\nThat's correct! I think my players will have a lot of fun creating all sorts of fun levels.\n\nTo recap, with the Generable macro, we can easily generate structured output from a Swift type that’s defined at compile time.\n\nAnd under the hood, Foundation Models takes care of the schema, and converting the GeneratedContent into an instance of your own type. Dynamic schemas work very similar, but give you much more control. You control the schema entirely at runtime, and get direct access to the GeneratedContent. Next, let’s take a look at tool calling, which can let the model call your own functions. I’m thinking of creating a DLC, downloadable content, to make my game more personal. Using tool calling, I can let the model autonomously fetch information. I’m thinking that integrating the player’s contacts and calendar could be really fun.\n\nI wouldn’t normally do that with a server-based model, my players wouldn’t appreciate it if the game uploaded such personal data. But since it’s all on-device with Foundation Models, we can do this while preserving privacy.\n\nDefining a tool is very easy, with the Tool protocol. You start by giving it a name, and a description. This is what will be put in the prompt, automatically by the API, to let the model decide when and how often to call your tool.\n\nIt’s best to make your tool name short, but still readable as English text. Avoid abbreviations, and don’t make your description too long, or explain any of the implementations. Because remember, these strings are put verbatim in your prompt. So longer strings means more tokens, which can increase the latency. Instead, consider using a verb in the name, such as findContact. And your description should be about one sentence. As always, it’s important to try different variations to checkout what works best for your specific tool.\n\nNext, we can define the input for our tool. I want the tool to get contacts from a certain age generation, like millennials. The model will be able to pick a funny case based on the game state, and I can add the Arguments struct, and make it Generable.\n\nWhen the model decides to call this tool, it will generate the input arguments. By using Generable, this guarantees your tool always gets valid input arguments. So it won’t make up a different generation, like gen alpha, which we don’t support in our game.\n\nThen I can implement the call function. The model will call this function when it decides to invoke the tool.\n\nIn this example, we’ll then call out to the Contacts API. And return a contact’s name for that query.\n\nTo use our tool, we’ll pass it in the session initializer. The model will then call our tool when it wants that extra piece of information.\n\nThis is more powerful than just getting the contact ourselves, because the model will only call the tool when it needs for a certain NPC, and it can pick fun input arguments based on the game state. Like the age generation for the NPC.\n\nKeep in mind, this is using the regular contacts API, which you might be familiar with. When our tool is first is invoked, it will ask the player for the usual permission. Even if the player doesn’t want to give access to their contacts, Foundation Models can still generate content like before, but if they do give access, we make it more personal.\n\nLet’s walk around a bit in our game until we encounter another NPC. And this time, I’ll get a name from my contacts! Oh hi there Naomy! Let’s checkout what she has to say, I didn’t know you liked coffee.\n\nNote that LanguageModelSession takes an instance of a tool. This means you control the lifecycle of the tool. The instance of this tool stays the same for the whole session.\n\nNow, in this example, because we’re just getting a random character with our FindContactsTool, it’s possible we’ll get the same contact sometimes. In our game, there are multiple Naomy’s now. And that’s not right, there can only be the one.\n\nTo fix this, we can keep track of the contacts the game has already used. We can add state to our FindContactTool. To do this, we will first convert our FindContactTool to be a class. So it can mutate its state from the call method.\n\nThen we can keep track of the picked contacts, and in our call method we don’t pick the same one again.\n\nThe NPC names are now based on my contacts! But talking to them doesn’t feel right yet. Let’s round this off with another tool, this time for accessing my calendar.\n\nFor this tool, we’ll pass in the contact name from a dialog that’s going on in our game. And when the model calls this tool, we’ll let it generate a day, month and a year for which to fetch events with this contact. And we’ll pass this tool in the session for the NPC dialog.\n\nSo now, if we ask my friend Naomy’s NPC \"What’s going on?\", she can reply with real events we have planned together.\n\nWow, it's like talking to the real Naomy now.\n\nLet’s take a closer look at how tool calling works.\n\nWe start by passing the tool at the start of the session, along with instructions. And for this example, we include information like today’s date.\n\nThen, when the user prompts the session, the model can analyze the text. In this example, the model understands that the prompt is asking for events, so calling the calendar tool makes sense.\n\nTo call the tool, the model first generates the input arguments. In this case the model needs to generate the date to get events for. The model can relate information from the instructions and prompt, and understand how to fill in the tool arguments based on that.\n\nSo in this example it can infer what tomorrow means based on today’s date in the instructions. Once the input for your tool is generated, your call method is invoked.\n\nThis is your time to shine, your tool can do anything it wants. But note, the session waits for your tool to return, before it can generate any further output.\n\nThe output of your tool is then put in the transcript, just like output from the model. And based on your tool’s output, the model can generate a response to the prompt.\n\nNote that a tool can be called multiple times for a single request.\n\nAnd when that happens, your tool gets called in parallel. So keep that in mind when accessing data from your tool’s call method.\n\nAlright, that was pretty fun! Our game now randomly generates content, based on my personal contacts and calendar. All without my data ever leaving my device. To recap, tool calling can let the model call your code to access external data during a request. This can be private information, like Contacts, or even external data from sources on the web. Keep in mind that a tool can be invoked multiple times, within a given request. The model determines this based on its context.\n\nTools can also be called in parallel, and they can store state.\n\nThat was quite a lot.\n\nPerhaps get a coffee before doing anything else.\n\nTo learn more, you can check out the dedicated video about prompt engineering, including design and safety tips. And, if you want to meet the real Naomy, check out the code-along video. I hope you will have as much fun with Foundation Models as I’ve had. Thanks for watching.",
    "segments": []
  },
  "codeExamples": [
    {
      "timestamp": "1:05",
      "title": "Prompting a session",
      "language": "swift",
      "code": "import FoundationModels\n\nfunc respond(userInput: String) async throws -> String {\n  let session = LanguageModelSession(instructions: \"\"\"\n    You are a friendly barista in a world full of pixels.\n    Respond to the player’s question.\n    \"\"\"\n  )\n  let response = try await session.respond(to: userInput)\n  return response.content\n}"
    },
    {
      "timestamp": "3:37",
      "title": "Handle context size errors",
      "language": "swift",
      "code": "var session = LanguageModelSession()\n\ndo {\n  let answer = try await session.respond(to: prompt)\n  print(answer.content)\n} catch LanguageModelSession.GenerationError.exceededContextWindowSize {\n  // New session, without any history from the previous session.\n  session = LanguageModelSession()\n}"
    },
    {
      "timestamp": "3:55",
      "title": "Handling context size errors with a new session",
      "language": "swift",
      "code": "var session = LanguageModelSession()\n\ndo {\n  let answer = try await session.respond(to: prompt)\n  print(answer.content)\n} catch LanguageModelSession.GenerationError.exceededContextWindowSize {\n  // New session, with some history from the previous session.\n  session = newSession(previousSession: session)\n}\n\nprivate func newSession(previousSession: LanguageModelSession) -> LanguageModelSession {\n  let allEntries = previousSession.transcript.entries\n  var condensedEntries = [Transcript.Entry]()\n  if let firstEntry = allEntries.first {\n    condensedEntries.append(firstEntry)\n    if allEntries.count > 1, let lastEntry = allEntries.last {\n      condensedEntries.append(lastEntry)\n    }\n  }\n  let condensedTranscript = Transcript(entries: condensedEntries)\n  // Note: transcript includes instructions.\n  return LanguageModelSession(transcript: condensedTranscript)\n}"
    },
    {
      "timestamp": "6:14",
      "title": "Sampling",
      "language": "swift",
      "code": "// Deterministic output\nlet response = try await session.respond(\n  to: prompt,\n  options: GenerationOptions(sampling: .greedy)\n)\n                \n// Low-variance output\nlet response = try await session.respond(\n  to: prompt,\n  options: GenerationOptions(temperature: 0.5)\n)\n                \n// High-variance output\nlet response = try await session.respond(\n  to: prompt,\n  options: GenerationOptions(temperature: 2.0)\n)"
    },
    {
      "timestamp": "7:06",
      "title": "Handling languages",
      "language": "swift",
      "code": "var session = LanguageModelSession()\n\ndo {\n  let answer = try await session.respond(to: userInput)\n  print(answer.content)\n} catch LanguageModelSession.GenerationError.unsupportedLanguageOrLocale {\n  // Unsupported language in prompt.\n}\n\nlet supportedLanguages = SystemLanguageModel.default.supportedLanguages\nguard supportedLanguages.contains(Locale.current.language) else {\n  // Show message\n  return\n}"
    },
    {
      "timestamp": "8:14",
      "title": "Generable",
      "language": "swift",
      "code": "@Generable\nstruct NPC {\n  let name: String\n  let coffeeOrder: String\n}\n\nfunc makeNPC() async throws -> NPC {\n  let session = LanguageModelSession(instructions: ...)\n  let response = try await session.respond(generating: NPC.self) {\n    \"Generate a character that orders a coffee.\"\n  }\n  return response.content\n}"
    },
    {
      "timestamp": "9:22",
      "title": "NPC",
      "language": "swift",
      "code": "@Generable\nstruct NPC {\n  let name: String\n  let coffeeOrder: String\n}"
    },
    {
      "timestamp": "10:49",
      "title": "Generable with enum",
      "language": "swift",
      "code": "@Generable\nstruct NPC {\n  let name: String\n  let encounter: Encounter\n\n  @Generable\n  enum Encounter {\n    case orderCoffee(String)\n    case wantToTalkToManager(complaint: String)\n  }\n}"
    },
    {
      "timestamp": "11:20",
      "title": "Generable with guides",
      "language": "swift",
      "code": "@Generable\nstruct NPC {\n  @Guide(description: \"A full name\")\n  let name: String\n  @Guide(.range(1...10))\n  let level: Int\n  @Guide(.count(3))\n  let attributes: [Attribute]\n  let encounter: Encounter\n\n  @Generable\n  enum Attribute {\n    case sassy\n    case tired\n    case hungry\n  }\n  @Generable\n  enum Encounter {\n    case orderCoffee(String)\n    case wantToTalkToManager(complaint: String)\n  }\n}"
    },
    {
      "timestamp": "13:40",
      "title": "Regex guide",
      "language": "swift",
      "code": "@Generable\nstruct NPC {\n  @Guide(Regex {\n    Capture {\n      ChoiceOf {\n        \"Mr\"\n        \"Mrs\"\n      }\n    }\n    \". \"\n    OneOrMore(.word)\n  })\n  let name: String\n}\n\nsession.respond(to: \"Generate a fun NPC\", generating: NPC.self)\n// > {name: \"Mrs. Brewster\"}"
    },
    {
      "timestamp": "14:50",
      "title": "Generable riddle",
      "language": "swift",
      "code": "@Generable\nstruct Riddle {\n  let question: String\n  let answers: [Answer]\n\n  @Generable\n  struct Answer {\n    let text: String\n    let isCorrect: Bool\n  }\n}"
    },
    {
      "timestamp": "15:10",
      "title": "Dynamic schema",
      "language": "swift",
      "code": "struct LevelObjectCreator {\n  var properties: [DynamicGenerationSchema.Property] = []\n\n  mutating func addStringProperty(name: String) {\n    let property = DynamicGenerationSchema.Property(\n      name: name,\n      schema: DynamicGenerationSchema(type: String.self)\n    )\n    properties.append(property)\n  }\n\n  mutating func addArrayProperty(name: String, customType: String) {\n    let property = DynamicGenerationSchema.Property(\n      name: name,\n      schema: DynamicGenerationSchema(\n        arrayOf: DynamicGenerationSchema(referenceTo: customType)\n      )\n    )\n    properties.append(property)\n  }\n  \n  var root: DynamicGenerationSchema {\n    DynamicGenerationSchema(\n      name: name,\n      properties: properties\n    )\n  }\n}\n\nvar riddleBuilder = LevelObjectCreator(name: \"Riddle\")\nriddleBuilder.addStringProperty(name: \"question\")\nriddleBuilder.addArrayProperty(name: \"answers\", customType: \"Answer\")\n\nvar answerBuilder = LevelObjectCreator(name: \"Answer\")\nanswerBuilder.addStringProperty(name: \"text\")\nanswerBuilder.addBoolProperty(name: \"isCorrect\")\n\nlet riddleDynamicSchema = riddleBuilder.root\nlet answerDynamicSchema = answerBuilder.root\n\nlet schema = try GenerationSchema(\n  root: riddleDynamicSchema,\n  dependencies: [answerDynamicSchema]\n)\n\nlet session = LanguageModelSession()\nlet response = try await session.respond(\n  to: \"Generate a fun riddle about coffee\",\n  schema: schema\n)\nlet generatedContent = response.content\nlet question = try generatedContent.value(String.self, forProperty: \"question\")\nlet answers = try generatedContent.value([GeneratedContent].self, forProperty: \"answers\")"
    },
    {
      "timestamp": "18:47",
      "title": "FindContactTool",
      "language": "swift",
      "code": "import FoundationModels\nimport Contacts\n\nstruct FindContactTool: Tool {\n  let name = \"findContact\"\n  let description = \"Finds a contact from a specified age generation.\"\n    \n  @Generable\n  struct Arguments {\n    let generation: Generation\n        \n    @Generable\n    enum Generation {\n      case babyBoomers\n      case genX\n      case millennial\n      case genZ            \n    }\n  }\n  \n  func call(arguments: Arguments) async throws -> ToolOutput {\n    let store = CNContactStore()\n        \n    let keysToFetch = [CNContactGivenNameKey, CNContactBirthdayKey] as [CNKeyDescriptor]\n    let request = CNContactFetchRequest(keysToFetch: keysToFetch)\n\n    var contacts: [CNContact] = []\n    try store.enumerateContacts(with: request) { contact, stop in\n      if let year = contact.birthday?.year {\n        if arguments.generation.yearRange.contains(year) {\n          contacts.append(contact)\n        }\n      }\n    }\n    guard let pickedContact = contacts.randomElement() else {\n      return ToolOutput(\"Could not find a contact.\")\n    }\n    return ToolOutput(pickedContact.givenName)\n  }\n}"
    },
    {
      "timestamp": "20:26",
      "title": "Call FindContactTool",
      "language": "swift",
      "code": "import FoundationModels\n\nlet session = LanguageModelSession(\n  tools: [FindContactTool()],\n  instructions: \"Generate fun NPCs\"\n)"
    },
    {
      "timestamp": "21:55",
      "title": "FindContactTool with state",
      "language": "swift",
      "code": "import FoundationModels\nimport Contacts\n\nclass FindContactTool: Tool {\n  let name = \"findContact\"\n  let description = \"Finds a contact from a specified age generation.\"\n   \n  var pickedContacts = Set<String>()\n    \n  ...\n\n  func call(arguments: Arguments) async throws -> ToolOutput {\n    contacts.removeAll(where: { pickedContacts.contains($0.givenName) })\n    guard let pickedContact = contacts.randomElement() else {\n      return ToolOutput(\"Could not find a contact.\")\n    }\n    return ToolOutput(pickedContact.givenName)\n  }\n}"
    },
    {
      "timestamp": "22:27",
      "title": "GetContactEventTool",
      "language": "swift",
      "code": "import FoundationModels\nimport EventKit\n\nstruct GetContactEventTool: Tool {\n  let name = \"getContactEvent\"\n  let description = \"Get an event with a contact.\"\n\n  let contactName: String\n    \n  @Generable\n  struct Arguments {\n    let day: Int\n    let month: Int\n    let year: Int\n  }\n    \n  func call(arguments: Arguments) async throws -> ToolOutput { ... }\n}"
    }
  ],
  "resources": {
    "resourceLinks": [
      {
        "title": "Design",
        "url": "https://developer.apple.com/design/"
      },
      {
        "title": "Generate dynamic game content with guided generation and tools",
        "url": "https://developer.apple.com/documentation/FoundationModels/generate-dynamic-game-content-with-guided-generation-and-tools"
      },
      {
        "title": "Human Interface Guidelines: Generative AI",
        "url": "https://developer.apple.com/design/human-interface-guidelines/generative-ai"
      },
      {
        "title": "Documentation",
        "url": "https://developer.apple.com/documentation/"
      },
      {
        "title": "Forums",
        "url": "https://developer.apple.com/forums/"
      },
      {
        "title": "Apple Design Awards",
        "url": "https://developer.apple.com/design/awards/"
      }
    ],
    "hdVideo": "https://devstreaming-cdn.apple.com/videos/wwdc/2025/301/4/955589c1-ae33-47db-9e86-2b87311dedb5/downloads/wwdc2025-301_hd.mp4?dl=1",
    "sdVideo": "https://devstreaming-cdn.apple.com/videos/wwdc/2025/301/4/955589c1-ae33-47db-9e86-2b87311dedb5/downloads/wwdc2025-301_sd.mp4?dl=1"
  },
  "relatedVideos": [
    {
      "id": "259",
      "year": "2025",
      "title": "Code-along: Bring on-device AI to your app using the Foundation Models framework",
      "url": "https://developer.apple.com/videos/play/wwdc2025/259"
    },
    {
      "id": "360",
      "year": "2025",
      "title": "Discover machine learning & AI frameworks on Apple platforms",
      "url": "https://developer.apple.com/videos/play/wwdc2025/360"
    },
    {
      "id": "286",
      "year": "2025",
      "title": "Meet the Foundation Models framework",
      "url": "https://developer.apple.com/videos/play/wwdc2025/286"
    }
  ],
  "extractedAt": "2025-07-18T10:39:02.136Z"
}