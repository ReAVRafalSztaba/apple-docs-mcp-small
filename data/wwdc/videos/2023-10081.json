{
  "id": "10081",
  "year": "2023",
  "url": "https://developer.apple.com/videos/play/wwdc2023/10081/",
  "title": "Enhance your spatial computing app with RealityKit",
  "speakers": [],
  "duration": "",
  "topics": [
    "Graphics & Games"
  ],
  "hasTranscript": true,
  "hasCode": true,
  "transcript": {
    "fullText": "♪ Mellow instrumental hip-hop ♪ ♪ Hello, my name is Yujin, and I'm an engineer on the RealityKit team.\n\nToday, I'm going to show you new features in RealityKit that you can use to enhance your spatial computing apps.\n\nSince the time we released RealityKit in 2019, We've seen apps use its rich feature set to create some amazing experiences.\n\nNow spatial computing adds even more features to RealityKit, like portals, particle emitters, RealityView attachments, and many more.\n\nIn the session titled \"Build spatial experiences with RealityKit,\" we learned about the basic building blocks of RealityKit: entities, which are container objects; components, which define specific behavior on entities; and systems, which act on both entities and components to add functionality.\n\nWe covered the RealityView API, which acts as a bridge between SwiftUI and RealityKit.\n\nWe also showed you how to add interaction, animations, and Spatial Audio to your RealityKit scene.\n\nIf you haven't watched it already, I highly recommend that you check out that session.\n\nIn this session, we will cover new features in RealityKit that will help make your app even more engaging and immersive.\n\nFirst, we will learn how to embed SwiftUI views into our RealityKit content using attachments in RealityView.\n\nNext, we will look at how to add video playback within our RealityKit scene.\n\nThen we will learn how to use portals to open a window to an alternate world.\n\nWe'll go through how to use the Particle Emitters API to enhance your scene with visual effects.\n\nFinally, we'll learn how to use anchors in RealityKit to attach 3D content to real-world locations, such as a wall.\n\nLet's get started with RealityView attachments.\n\nAttachments are a useful way to embed SwiftUI content into your RealityKit scene.\n\nIn this example app, I've used attachments to put text labels beneath the models of the earth and moon.\n\nI've also attached a view that explains how the moon affects tides on our ocean.\n\nLet's see how to make this in code.\n\nInside of my app, I'm using a RealityView to render my earth model.\n\nA RealityView is a view that lets us add RealityKit entities.\n\nEntities need to be added to a RealityView in order to be rendered, animated, and simulated.\n\nHere we simply load an entity for the earth and add it to the RealityView's content.\n\nLet's now change our RealityView to use attachments.\n\nAttachments are views that can be placed at specific locations relative to your RealityKit content.\n\nThere are two parts to setting up attachments.\n\nFirst, there's the added parameter in the make closure of our RealityView.\n\nSecond, there's an attachments view builder that is added to our RealityView.\n\nLet's cover the attachments view builder first.\n\nHere you can provide SwiftUI views that you want to add to your RealityKit content.\n\nIn this example, I've added a text view to label the Earth.\n\nWe'll also add a tag modifier to the view so that we can later identify it when our view gets delivered to the make closure as an entity.\n\nThis tag can be any hashable value.\n\nHere I've used the string earth_label.\n\nIn the make closure of our RealityView, the attachments parameter contains our views that are now represented as entities.\n\nTo get our view in entity form, we call entity(for:) on our attachments and pass in the same tag that we provided in the view builder, earth_label.\n\nThe result that we get is a view attachment entity, which we can add to our RealityKit content, just like any other entity.\n\nTo make the label appear beneath the earth, we'll add the attachment as a child of our earth entity and position it slightly below.\n\nWe can now repeat this process for all the other attachments we want to add using a different tag for each.\n\nLet's take a look in Xcode.\n\nIn my sample app, I'll add three attachments to my RealityView.\n\nFirst, I'll add a label below the earth.\n\nI'll also do the same for the moon.\n\nFinally, I'll add a short paragraph explaining the role of the moon's orbit on the tides.\n\nI've styled this using a glassBackgroundEffect in SwiftUI.\n\nIn the make closure of the RealityView, I'll add the corresponding entities to my content.\n\nFirst, I'll add the earthAttachment below the earth.\n\nI'll do the same for the moon.\n\nFinally, I'll place the tides explainer to the left of my container entity.\n\nI'll build and run my app, and we'll see the attachments that I've created displayed next to my models.\n\nLet's recap the data flow for attachments.\n\nAttachments start off in the attachments view builder in our RealityView.\n\nHere, we can provide SwiftUI views that we want to add to our RealityKit scene.\n\nIn the make closure of our RealityView, we get the attachments back as entities, which we can then add to our scene.\n\nWe can also update the entities inside of the update closure.\n\nThis closure is called when there are changes to our SwiftUI view state.\n\nYou can use this to respond to dynamically changing content in your RealityView.\n\nFor a more detailed usage of attachments, check out the session \"Work with Reality Composer Pro content in Xcode.\" RealityView attachments are a useful way of adding text content in other UI elements to a scene.\n\nAdditionally, we can also add a video to our app to make it more engaging.\n\nTo do this, let's use VideoPlayerComponent.\n\nVideo player component is a new component type in RealityKit that is used for embedding video content inside of a 3D scene.\n\nAs a reminder, components define specific behavior that you can attach to entities.\n\nTo play a video using VideoPlayerComponent, we'll first load a video file from our resources bundle.\n\nThen we'll use that to create an AVPlayer instance.\n\nWith it, we can now create a VideoPlayerComponent.\n\nWhen you attach a VideoPlayerComponent to an entity, a rectangular mesh that matches the aspect ratio of the video is automatically generated for you.\n\nThis behavior is analogous to existing video player APIs, such as VideoPlayer in SwiftUI and AVPlayerLayer in Core Animation.\n\nHowever, since RealityKit is a 3D framework, your video will be represented as an entity with a mesh so that you can move and position it in 3D space.\n\nAll video formats that are supported by AV Foundation will work with VideoPlayerComponent, including 2D video formats and 3D video using MV-HEVC.\n\nFinally, VideoPlayerComponent will automatically display captions that are provided through the AVPlayer.\n\nTo learn more about how to create your own video content, including 3D videos, check out the session entitled \"Deliver video content for spatial experiences.\" To add video to my RealityKit scene, we'll first create an AVPlayerItem using the URL to my video asset.\n\nWe'll then create an AVPlayer.\n\nOn the entity, we'll add a VideoPlayerComponent initialized with the AVPlayer that we just created.\n\nVideoPlayerComponent will automatically generate a mesh that is sized based on the aspect ratio of my video.\n\nBecause RealityKit works in real-world units, by default, the video will be one meter in height.\n\nTo make the video a different size, we can scale the entity.\n\nIn my case, I'd like the video to be 40 centimeters tall, so we'll multiply the entity scale by 0.4.\n\nFinally, we're ready to play the video.\n\nWe'll set the current item to our AVPlayerItem, and then call play on the AVPlayer.\n\nLet's rebuild and run our app with this code.\n\nI've added a Learn More button to our app, which will add the video entity to our scene.\n\nOn button click, I'll fade in the video using an opacity component and a fromToByAnimation.\n\nFor our video content, I've prepared a short clip that explains the role of the Moon's gravitational force on the Earth's rising tides.\n\nLet's take a look.\n\nThe moon orbits our planet.\n\nIts gravitational pull exerts a powerful force on our oceans, causing it to bulge ever so slightly towards the lunar sphere. < VideoPlayerComponent respects the systemwide preferences for captions.\n\nLet's turn them on in the Settings app under the Accessibility section.\n\nAnd so it is, that twice a day, in a never-ending cycle, the tides rise and fall, driven by this unceasing interplay of earth and moon. < VideoPlayerComponent also supports passthrough tinting.\n\nWhen this feature is enabled, your passthrough content is adjusted to match colors in the video.\n\nThis is the same treatment that is used when watching movies and TV shows inside of the TV app on this platform.\n\nTo use passthrough tinting, you can set the isPassthroughTintingEnabled property to true.\n\nYou can also subscribe to VideoPlayerEvents to be notified when properties on a VideoPlayerComponent change, such as the content type, viewing mode, and video size.\n\nTo subscribe to events, you can call the subscribe function on your RealityViews content and specify the event type and entity.\n\nYou can respond to events inside of the event handler closure.\n\nVideoPlayerComponent is a great addition to our 3D scene.\n\nSo far, our app features a model of the earth and moon, but I'd like to present it against a backdrop of outer space.\n\nI think it would be pretty cool if we can make ourselves a magic window in the room that reveals the moon's orbit in outer space.\n\nWe can do this using a portal to render our scene.\n\nA portal creates an opening to a different world that is visible through a mesh surface.\n\nEntities inside of this world use separate lighting and are masked by the portal's geometry.\n\nThis example demonstrates three distinct features in RealityKit.\n\nFirst, a portal is used to render the scene in outer space.\n\nThen a particle effect is used to decorate the rim of the portal.\n\nFinally, anchoring is used to place the portal on the wall of our room.\n\nLet's start with portals.\n\nTo make a portal, we must first create a world.\n\nTo do this, we add an entity in our scene that has a World component.\n\nThis component marks its entity tree as belonging to a different world.\n\nEntities in a world are only visible through a portal surface.\n\nTo add content to our world, we can attach entities as children of the world entity.\n\nHere, we'll add models for the sky, earth, and moon, as well as an ImageBasedLight to define the lighting inside of the world.\n\nAll descendants of the world entity will appear only inside of this world.\n\nNext, we'll make a portal.\n\nTo do this, we add an entity with a model component.\n\nThe model component contains two properties, a mesh and a material.\n\nFor the mesh, we'll generate a circular plane to act as the surface of the portal.\n\nFor the material, we'll assign a new portal material in order to make the mesh appear as a portal.\n\nTo connect the portal with our world, we'll add a portal component to the entity and set its target property to the world entity.\n\nThis allows the portal to act as a mask to reveal the content inside of our world.\n\nLet's see how this looks in code.\n\nIn our RealityView, I've added calls to two functions that will implement makeWorld and makePortal.\n\nIn our makeWorld function, we'll create a world entity and populate it with the portal's contents.\n\nIn the makePortal function, we'll create a portal and link it to the world that we just created.\n\nFinally, we'll add both of these entities to our RealityView's content.\n\nLet's dive into each of these functions.\n\nInside of the makeWorld function, we create an entity and attach a WorldComponent.\n\nNext, we load an EnvironmentResource to use as our ImageBasedLight.\n\nWe'll apply this to the world using the ImageBasedLight component and ImageBasedLight ReceiverComponent.\n\nTo learn more about image-based lighting in RealityKit, check out the session \"Explore rendering for spatial computing.\" Next, we'll populate the world with our contents.\n\nI'll load models for the earth, moon, and sky, and add them to the world as children.\n\nBecause these entities are children of the world, they will only be visible through the portal.\n\nLet's move on to the makePortal function.\n\nTo make a portal, we first need a mesh.\n\nWe'll create one by making a model component for the entity.\n\nTo make our portal circular, we'll generate a plane with equal dimensions and a corner radius that is half the size.\n\nI'll also create a PortalMaterial to use as a material for the ModelComponent.\n\nFinally, we'll also attach a portal component that is initialized with the world entity that we created earlier.\n\nThis links the portal with the world so that we can see the world's contents through the mesh.\n\nNext, let's decorate the rim of the portal with a particle effect.\n\nTo do this, we can use the ParticleEmitterComponent provided in RealityKit.\n\nParticle emitters can be used to represent many different visual effects in RealityKit, such as sparks, snow, and impact effects.\n\nParticle emitters can be created either via Reality Composer Pro or at runtime using RealityKit through the ParticleEmitterComponent Here, I've prepared a particle asset using Reality Composer Pro.\n\nWe can use this to decorate the portal that we created earlier.\n\nLet's load this into our scene and modify the particle properties at runtime using RealityKit.\n\nTo update the particles over time, I've created a custom system called ParticleTransitionSystem.\n\nHere, we'll use an EntityQuery to find entities that have a ParticleEmitterComponent.\n\nInside of the system update, we'll perform our query and iterate over the resulting entities.\n\nOn each entity, we'll call the function updateParticles, which we will implement next.\n\nTo learn more about custom systems in RealityKit, check out the session \"Build spatial experiences with RealityKit.\" Inside of our updateParticles function, we'll first get the ParticleEmitterComponent from the entity.\n\nThe ParticleEmitterComponent contains many properties that control various aspects of particle look and behavior.\n\nHere, we'll set the lifeSpan and vortexStrength properties based on the entity's scale, so that as the entity grows in size, the particles start spinning faster around the portal.\n\nFinally, let's apply our changes by assigning the component back to the entity.\n\nAnd we are set.\n\nTo learn about all the different properties on particle emitters, check out the session \"Meet Reality Composer Pro.\" We're almost done adding the final touch to our app.\n\nTo finish, let's attach our portal to the wall in our room.\n\nTo do this, we can use anchors in RealityKit.\n\nAnchors can be used to place content on walls, floors, or locations relative to your head or hand.\n\nAnchors in RealityKit support two tracking modes, .continuous and .once.\n\nWhen using the continuous tracking mode, the anchor entity moves along with the anchor over time, such as when your head moves.\n\nWhen using the once tracking mode, the anchor entity will not move after being positioned once.\n\nTo listen to when an entity becomes anchored, you can subscribe to the AnchoredStateChanged event in RealityKit.\n\nNote that while you can use anchors to parent entities to place 3D content, explicit transforms of the anchors themselves are not visible to the app to preserve user privacy.\n\nTo get access to anchor transforms, you will need to use ARKit.\n\nFor more information on this, check out the session, \"Meet ARKit for spatial computing.\" To use anchors in our app, we first need to modify our app to use an immersive space.\n\nAn immersive space is a special type of container that allows your app to render content outside of the window.\n\nTo do this, we can add an ImmersiveSpace to our SwiftUI scene.\n\nWe'll also add an .immersionStyle modifier and set it to mixed.\n\nInside of the ImmersiveSpace, we can use a RealityView to place content that will be anchored.\n\nTo learn more about Immersive Spaces, check out the session \"Go beyond the window with SwiftUI.\" Inside of our RealityView, we can use an anchor entity as a container for our portal.\n\nWe initialize an anchor entity with a specification of the type of surface that we would like to anchor our content on.\n\nIn our case, we are looking for a vertical wall with a minimum size of one meter by one meter.\n\nWhen an anchor is found that matches the specification, RealityKit will automatically attach our content to the wall.\n\nAnd we are finally done.\n\nWhen we run our app, we get a portal that is attached to the wall.\n\nFrom portals and particles to anchors and attachments, RealityKit provides many features that let you build immersive experiences.\n\nLet's summarize everything that we went over in this session.\n\nAttachments in RealityView let you embed SwiftUI content inside of your entity hierarchy so that you can place UI elements alongside 3D elements.\n\nVideoPlayerComponent, portals, and particle effects let you add dynamic elements to enhance your scene in RealityKit.\n\nFinally, anchors let you attach 3D content to real-world surfaces such as your floor or wall.\n\nThe session \"Build spatial experiences with RealityKit\" goes over key concepts like entities, components, and RealityView.\n\nThe session \"Work with Reality Composer Pro content in Xcode\" takes you through the process of building an immersive app using Reality Composer Pro together with RealityKit.\n\nI can't wait to see all the things you'll create using these new features in RealityKit.\n\nThank you for watching.\n\n♪",
    "segments": []
  },
  "codeExamples": [
    {
      "timestamp": "2:30",
      "title": "Attachments",
      "language": "swift",
      "code": "import SwiftUI\nimport RealityKit\n\nstruct MoonOrbit: View {\n    var body: some View {\n        RealityView { content, attachments in\n            guard let earth = try? await Entity(named: \"Earth\") else {\n                return\n            }\n            content.add(earth)\n\n            if let earthAttachment = attachments.entity(for: \"earth_label\") {\n                earthAttachment.position = [0, -0.15, 0]\n                earth.addChild(earthAttachment)\n            }\n        } attachments: {\n            Attachment(id: \"earth_label\") {\n                Text(\"Earth\")\n            }\n        }\n    }\n}"
    },
    {
      "timestamp": "8:03",
      "title": "VideoPlayerComponent",
      "language": "swift",
      "code": "public func makeVideoEntity() -> Entity {\n    let entity = Entity()\n\n    let asset = AVURLAsset(url: Bundle.main.url(forResource: \"tides_video\",\n                                                withExtension: \"mp4\")!)\n    let playerItem = AVPlayerItem(asset: asset)\n\n    let player = AVPlayer()\n    entity.components[VideoPlayerComponent.self] = .init(avPlayer: player)\n\n    entity.scale *= 0.4\n\n    player.replaceCurrentItem(with: playerItem)\n    player.play()\n\n    return entity\n}"
    },
    {
      "timestamp": "10:05",
      "title": "Passthrough tinting",
      "language": "swift",
      "code": "var videoPlayerComponent = VideoPlayerComponent(avPlayer: player)\n    videoPlayerComponent.isPassthroughTintingEnabled = true\n\n    entity.components[VideoPlayerComponent.self] = videoPlayerComponent"
    },
    {
      "timestamp": "10:40",
      "title": "VideoPlayerEvents",
      "language": "swift",
      "code": "content.subscribe(to: VideoPlayerEvents.VideoSizeDidChange.self,\n                      on: entity) { event in\n        // ...\n    }"
    },
    {
      "timestamp": "13:12",
      "title": "Portal",
      "language": "swift",
      "code": "struct PortalView : View {\n    var body: some View {\n        RealityView { content in\n            let world = makeWorld()\n            let portal = makePortal(world: world)\n\n            content.add(world)\n            content.add(portal)\n        }\n    }\n}\n\npublic func makeWorld() -> Entity {\n    let world = Entity()\n    world.components[WorldComponent.self] = .init()\n\n    let environment = try! EnvironmentResource.load(named: \"SolarSystem\")\n    world.components[ImageBasedLightComponent.self] = .init(source: .single(environment),\n                                                            intensityExponent: 6)\n    world.components[ImageBasedLightReceiverComponent.self] = .init(imageBasedLight: world)\n\n    let earth = try! Entity.load(named: \"Earth\")\n    let moon = try! Entity.load(named: \"Moon\")\n    let sky = try! Entity.load(named: \"OuterSpace\")\n    world.addChild(earth)\n    world.addChild(moon)\n    world.addChild(sky)\n\n    return world\n}\n\npublic func makePortal(world: Entity) -> Entity {\n    let portal = Entity()\n\n    portal.components[ModelComponent.self] = .init(mesh: .generatePlane(width: 1,\n                                                                        height: 1,\n                                                                        cornerRadius: 0.5),\n                                                   materials: [PortalMaterial()])\n    portal.components[PortalComponent.self] = .init(target: world)\n\n    return portal\n}"
    },
    {
      "timestamp": "15:50",
      "title": "Adding particles around the portal",
      "language": "swift",
      "code": "public class ParticleTransitionSystem: System {\n    private static let query = EntityQuery(where: .has(ParticleEmitterComponent.self))\n\n    public func update(context: SceneUpdateContext) {\n        let entities = context.scene.performQuery(Self.query)\n        for entity in entities {\n            updateParticles(entity: entity)\n        }\n    }\n}\n\npublic func updateParticles(entity: Entity) {\n    guard var particle = entity.components[ParticleEmitterComponent.self] else {\n        return\n    }\n\n    let scale = max(entity.scale(relativeTo: nil).x, 0.3)\n\n    let vortexStrength: Float = 2.0\n    let lifeSpan: Float = 1.0\n    particle.mainEmitter.vortexStrength = scale * vortexStrength\n    particle.mainEmitter.lifeSpan = Double(scale * lifeSpan)\n\n    entity.components[ParticleEmitterComponent.self] = particle\n}"
    },
    {
      "timestamp": "18:19",
      "title": "Anchoring the portal",
      "language": "swift",
      "code": "import SwiftUI\nimport RealityKit\n\nstruct PortalApp: App {\n\n    @State private var immersionStyle: ImmersionStyle = .mixed\n\n    var body: some SwiftUI.Scene {\n        ImmersiveSpace {\n            RealityView { content in\n                let anchor = AnchorEntity(.plane(.vertical, classification: .wall,\n                                                 minimumBounds: [1, 1]))\n                content.add(anchor)\n\n                anchor.addChild(makePortal())\n            }\n        }\n        .immersionStyle(selection: $immersionStyle, in: .mixed)\n    }\n}"
    }
  ],
  "resources": {
    "resourceLinks": [
      {
        "title": "Design",
        "url": "https://developer.apple.com/design/"
      },
      {
        "title": "Diorama",
        "url": "https://developer.apple.com/documentation/visionOS/diorama"
      },
      {
        "title": "Documentation",
        "url": "https://developer.apple.com/documentation/"
      },
      {
        "title": "Forums",
        "url": "https://developer.apple.com/forums/"
      },
      {
        "title": "Apple Design Awards",
        "url": "https://developer.apple.com/design/awards/"
      }
    ],
    "hdVideo": "https://devstreaming-cdn.apple.com/videos/wwdc/2023/10081/4/218C691E-8111-4A1A-925F-F43AB9832C41/downloads/wwdc2023-10081_hd.mp4?dl=1",
    "sdVideo": "https://devstreaming-cdn.apple.com/videos/wwdc/2023/10081/4/218C691E-8111-4A1A-925F-F43AB9832C41/downloads/wwdc2023-10081_sd.mp4?dl=1"
  },
  "relatedVideos": [
    {
      "id": "10080",
      "year": "2023",
      "title": "Build spatial experiences with RealityKit",
      "url": "https://developer.apple.com/videos/play/wwdc2023/10080"
    },
    {
      "id": "10071",
      "year": "2023",
      "title": "Deliver video content for spatial experiences",
      "url": "https://developer.apple.com/videos/play/wwdc2023/10071"
    },
    {
      "id": "10095",
      "year": "2023",
      "title": "Explore rendering for spatial computing",
      "url": "https://developer.apple.com/videos/play/wwdc2023/10095"
    },
    {
      "id": "10111",
      "year": "2023",
      "title": "Go beyond the window with SwiftUI",
      "url": "https://developer.apple.com/videos/play/wwdc2023/10111"
    },
    {
      "id": "10082",
      "year": "2023",
      "title": "Meet ARKit for spatial computing",
      "url": "https://developer.apple.com/videos/play/wwdc2023/10082"
    },
    {
      "id": "10083",
      "year": "2023",
      "title": "Meet Reality Composer Pro",
      "url": "https://developer.apple.com/videos/play/wwdc2023/10083"
    },
    {
      "id": "10113",
      "year": "2023",
      "title": "Take SwiftUI to the next dimension",
      "url": "https://developer.apple.com/videos/play/wwdc2023/10113"
    },
    {
      "id": "10273",
      "year": "2023",
      "title": "Work with Reality Composer Pro content in Xcode",
      "url": "https://developer.apple.com/videos/play/wwdc2023/10273"
    }
  ],
  "extractedAt": "2025-07-18T10:30:25.543Z"
}