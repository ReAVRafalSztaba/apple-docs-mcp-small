{
  "id": "344",
  "year": "2025",
  "url": "https://developer.apple.com/videos/play/wwdc2025/344/",
  "title": "Record, replay, and review: UI automation with Xcode",
  "speakers": [],
  "duration": "",
  "topics": [
    "Developer Tools"
  ],
  "hasTranscript": true,
  "hasCode": true,
  "transcript": {
    "fullText": "Hey, I’m Max, and I’m an engineer on the Xcode team. There are so many awesome features and experiences inside of Xcode, it can be overwhelming. For example, did you know it’s possible to watch your app run on dozens of devices, languages, and configurations with one click? And on top of that, you can get a full quality video recording of every single run. Well, that’s totally possible with the power of UI automation in Xcode. Let's take a look at how that works. First, we’ll cover an overview of UI automation. Then we’ll prepare your app, record your interactions as automation code, replay the automation across several devices and languages, and finally, watch video recordings of the results and see a report about whether each run passed or failed.\n\nLet’s start with an overview of how UI automation works.\n\nInside Xcode, we have two testing frameworks: Swift Testing and XCTest. Both frameworks are capable of quickly testing your app and your source code in many configurations.\n\nWhen you import XCTest, a framework called XCUIAutomation is automatically included. XCUIAutomation can be used to automate your app and interact with it like a person does. These frameworks work together to provide a complete app testing suite, and if you ask me, I think that’s pretty sweet.\n\nA complete app testing suite is usually comprised of both unit and UI automation tests. Unit tests test your app’s logic and models, and with Swift testing, it’s possible to run tests on frameworks and Swift packages that don’t even have a user interface.\n\nMeanwhile, UI automation tests validate your app’s user experience, as well as its integration with Apple hardware and the behavior of common workflows.\n\nGenerally, your test suite will have more unit tests than UI tests, and you want to aim for full coverage of your code. But UI automation tests let you see how your app looks, behaves, and integrates with the rest of the operating system. There are so many benefits to doing this.\n\nFor example, you can test your app as a person would with gestures like taps, swipes and clicks. You can understand how your app is perceived by people who use assistive technologies like VoiceOver, Voice Control, and Dynamic Type.\n\nYou can view your app running on all of the languages and regions that it supports and focus on languages that have large effects on the look of your app, like languages with longer strings and languages with a right-to-left layout. You can test your app’s integration with Apple hardware features, like the Action button, camera button, Apple TV remote, and Apple Watch’s Digital Crown. And finally, you can test your app’s launch performance, which is a key metric in understanding how quickly people can get started using your app. To set up a UI automation workflow, there are three key phases: record, replay, and review.\n\nFirst, record your interactions like taps, swipes, and hardware button presses, then watch Xcode automatically write those as code. Then, replay your interactions across multiple devices, languages, regions, and device orientations, both on your devices and in Xcode Cloud. Finally, review videos and results of your app running in all of those configurations and see which ones passed and which ones failed.\n\nUI automation is supported on all Apple platforms: iOS, iPadOS, macOS, watchOS, tvOS, and visionOS (Designed for iPad). The same automation can even run on multiple platforms. So it’s possible to build an automation once and run it on all your supported devices. That means you can see how your app runs on Mac, iPhone and Vision Pro with one click and no code changes. Let’s briefly go over how UI automation works.\n\nUI automation interacts with your app as a person does using gestures and hardware events. Automation runs completely independently from your app, so your app models and data are not directly accessible.\n\nUI automation tells the operating system which gestures to perform, then synchronously waits for them to complete one at a time.\n\nThese actions include launching your app, interacting with buttons and navigation, setting system state like Dark Mode, and even setting a simulated location for the device if you wanted to. At Apple, accessibility is one of our core values. Apple’s assistive technologies make sure that everyone can use your app regardless of any physical, visual, audible or motor impairment. We work really hard to ensure that most of these technologies work with your app by default, with no work needed from you as a developer. That said, adding additional support can enrich your app’s experience and make it even easier to automate. The thing is, accessibility is the underlying framework that powers UI automation. Having a great accessibility experience means you get a great UI automation experience too.\n\nAccessibility provides information directly to UI automation, such as element types, labels, values and frames but what accessibility sees is not necessarily one-to-one with what you see as a person.\n\nLet’s take a look at an example. On this screen, the Great Barrier Reef button is visible in the UI but accessibility can see even more than that. Sure, accessibility can see the elements type and label and expose them to UI automation but the identifier property is also exposed. The accessibility identifier can be used to describe any element on screen uniquely, relative to all the elements around it. The identifier is not designed to be localized, so you can use it to refer to the same UI element in any language or device.\n\nFor checkboxes and other stateful elements, a value property can be used. This reveals the element’s current state to both accessibility and UI automation.\n\nTo learn way more about accessibility, check out “Build accessible apps with SwiftUI and UIKit” from WWDC23, or “SwiftUI Accessibility: Beyond the basics” from WWDC21.\n\nNow that we’ve explored how a UI automation works with accessibility, let’s prepare your app automation.\n\nFirst, we’ll add accessibility identifiers. Then we’ll do a quick review of your app’s accessibility. And finally, we’ll add a new UI testing target to get ready to record our interactions as code. Before we dive in, it's worth noting that your app already fully supports UI automation and UI recording out of the box with no work needed from you as a developer. The steps we’re about to cover are not required but they can lead to better and higher-quality results. Adding accessibility identifiers can be done in your view code written in SwiftUI, UIKit or AppKit. Accessibility identifiers are the best way to uniquely identify any element in your app for automation. It’s a good idea to add accessibility identifiers to elements with localized strings or dynamic content. That includes content found in any of your data models or content that’s downloaded from the internet.\n\nGood identifiers are unique within your entire app, descriptive enough to detail the element that they are on, and static, not reacting to changes in content.\n\nWhile titles and descriptions might change, good identifiers always describe the contents of the element they are attached to. That way, we can be sure my lovely landmarks stick around forever.\n\nIn SwiftUI, you can add the accessibilityIdentifier modifier to any UI element. It will be recognized as long as your view and its parent views are not hidden from accessibility.\n\nIt’s a good idea to make identifiers specific to an instance of a view, especially for views that are used many times in your app. In this example, we use the landmark’s id property to make the identifier unique for each one.\n\nIn UIKit, the accessibilityIdentifier property can be set on any UIView as long as the view is an accessibility element. Most UI views, like controls, text and images, are accessibility elements by default so usually no work is needed to do this.\n\nProperties like accessibilityLabel, accessibilityTraits and accessibilityValue are useful to assistive technologies like VoiceOver and are also useful to UI automation.\n\nHowever, the accessibilityIdentifier property is not read out loud by VoiceOver and is not exposed to anyone using your app. This makes it a useful way to provide information that is only useful to automation, like the index of a table cell or the symbol name of an image. I can even have the coding assistant in Xcode add accessibility identifiers for me. For example, I can write, “Add accessibility identifiers to the relevant parts of this view”, and it will just happen. The coding assistant even knows how to use the id property on a landmark to make each identifier completely unique. Pretty cool. Reviewing your app’s overall accessibility behavior is a good idea before starting UI recording. It’s like flossing before going to the dentist. You’re going to know exactly how well you’ve been doing soon. This will just give you a good preview of it. Xcode ships with an app called Accessibility Inspector, which lets you find, diagnose and fix accessibility issues. The Inspector can be launched from the Xcode top-level menu under Open Developer Tool. It can also be launched from Spotlight.\n\nAccessibility Inspector can list the accessibility values for any view in your app on any platform. Simply select the platform you wish to inspect, then click the Element inspector and interact with the UI element you want to learn about on that platform. A list of element properties will be displayed. Some of them, like the ones in the Basic section, are really useful to UI automation. For views that are lacking information, you may want to change your app’s source code and add some. You can find out details about each property by clicking a property’s name. The popover will tell you exactly which property to set, provide documentation about it and more.\n\nYou can learn even more about accessibility features with our sample code project, “Delivering an exceptional accessibility experience.” This project provides some great code examples for an app that uses many accessibility features and is really friendly to UI automation. Also, check out the article, “Performing accessibility testing for your app” to learn about ways to check your app’s accessibility using a bunch of different assistive technologies. Once we’re ready to start automating, we need to add a new UI testing target to have somewhere to put our automation code.\n\nIn the project settings view in Xcode, add a new target with the “plus” button below the targets list.\n\nThen select UI Testing Bundle from the popover.\n\nOnce you click Finish, a new UI test folder and template will be added to your project.\n\nThe template has some simple tests to help you get started. Okay, now we’re ready to magically record all of our interactions as Swift code. Let’s use iOS Simulator and Xcode for this. A few years ago, my mom and sister went on a month-long trip to Australia without me, and I’m pretty bummed I didn’t get to go with them. Lucky for me, there's an app for that. I can use the Landmarks sample project from this year’s WWDC to plan a vacation of my own. I’ll record some interactions that plan my trip so I can ensure that workflow doesn’t break in future versions of the app. When I open the UI test source file for the first time, a popover will appear telling me how I can start a UI recording. Now, I’ll start a UI recording using the button in the sidebar, and Xcode will automatically build and relaunch my app in Simulator.\n\nNow that my app is launched, I'll go to the collections view.\n\nAs I interact with the app, the code representing my interactions is recorded in the source editor. I’ll tap the Plus button to add a new collection to start planning my own trip to Australia. Now I’ll tap the Edit button to rename the trip, and I can rename the trip “Max’s Australian Adventure”.\n\nXcode will keep my test up-to-date as I keep typing.\n\nNow I'll edit the collection of landmarks.\n\nJust add some Australian landmarks like the Great Barrier Reef and Uluru and tap the check mark.\n\nOnce I go back to the collections view, I can see that my collection has been added with some Australian landmarks included.\n\nYou can stop UI recording with the Stop Run button in Xcode. After you finish recording, there are a few things you might want to do to make sure you got the automation you wanted. First, review the recorded code. Then add validations using XCTest APIs to ensure your app is behaving as you expected it to. And finally, explore other automation APIs that can make your test even more powerful.\n\nLet’s review the UI queries that were recorded and see if I want to make any adjustments.\n\nEvery line of recorded code will have multiple options to address each UI element, and which one you choose depends on your goals. You can click the dropdown on each line of source code to see the choices.\n\nQuick hint, choosing the right one will help you board your plane to Australia faster.\n\nWe have a few recommendations to help you select from the options.\n\nFor views that have localized strings, like text elements or buttons, we recommend choosing an accessibility identifier if there is one. UI recording tries to use the identifier by default if one exists.\n\nFor views that are deeply nested, like text in scroll views, we recommend choosing the shortest possible query. This will help your automation stay resilient as your app changes.\n\nLastly, for dynamic content that is downloaded from the internet or content that changes frequently, like timestamps or the temperature, we recommend using a more generic query or an accessibility identifier if one is present.\n\nIn this example, we don’t even use an identifier or any string at all, and we always just refer to the first piece of text.\n\nOkay, now it's time to make a selection. I’ll click the line of source code I want to edit to see the options. All of these queries uniquely identify the element you interacted with, so there's really no wrong choice. It’s just about choosing how you want to store a reference to this piece of UI for the future. I’ll select the textFields.firstMatch option to make sure the text field is always tapped in my test no matter what it’s called. Double click any of the dropdowns to store this result in your source code. Now let's quickly rerun my automation to see if it recorded my actions correctly. I'll click the test diamond to run it. While we might be testing your app, we aren't trying to test your patience. The automation replay runs really fast.\n\nThe collection gets quickly created with the correct name, the locations get added, and the automation passes. Awesome.  That was way faster than a 19-hour flight. Now we can add validations to the code to check the expected behavior. In this example, I’ll validate that the Great Barrier landmark was added to my collection.\n\nI can call methods like waitForExistence to have my automation wait for an element to appear before moving on. I can also call the more generic method, wait(for:toEqual:) to validate that any property on an XCUIElement matches the expected result.\n\nI can pair both of these methods with XCTAssert statements from XCTest to fail the test if these methods return false.\n\nNow, let me go back to my code and quickly add a waitForExistence on the name of my collection to make sure it’s always there in future runs.\n\nNow is a good time to explore other automation APIs to make your code even more powerful.\n\nIt can be useful to use the setup instance method of an XCTestCase to make sure the device is in the same state in future runs. I can call APIs like orientation, appearance or even simulate a location to get my device into the correct state before a run starts.\n\nBefore launching my app, I can use properties like launchArguments and launchEnvironment to have my app use those parameters when the launch method is called.\n\nIf your app supports a custom URL scheme, you can open it to a matching URL directly using the XCUIApplication open method.\n\nThere’s even a global version, which opens a URL using the device’s default app for it.\n\nLastly, it’s possible to perform an accessibility audit of your app inside a UI test. There’s a great session on that called “Perform accessibility audits for your app” from WWDC23. Now that we’ve recorded our interactions and set up our automation, let’s configure the tests to replay in multiple configurations, both at-desk and in the cloud. It's really useful to add your test to a new or existing test plan. Test plans let you include or exclude individual tests, set system settings for where and how your tests run, and manage test properties like timeouts, repetitions, parallelization, execution order and more.\n\nTest plans are also associated with a scheme, which lets you pair a test plan with specific build settings.\n\nYou can learn a lot more about this with the article, “Improving code assessment by organizing tests into test plans” in our developer documentation.\n\nIn your test plan, you can add or remove tests on the first screen or switch to the Configurations tab to make changes to how the test will run.\n\nI can set up multiple configurations to run my app in multiple languages.\n\nTypically, each locale exists as a separate configuration in your test plan.\n\nYou can have settings that are focused for a specific locale configuration or other settings that are shared across all of them.\n\nIt can be helpful to include configurations for languages with longer strings, like German, or right-to-left languages, like Arabic and Hebrew.\n\nThere are even UI automation-focused settings in the Configurations tab.\n\nThese include whether to capture a video or screenshots during the run and whether any media will be kept afterwards.\n\nBy default, videos and screenshots are only kept for failing runs, to let you review any issues. If you want to keep them for all runs, even runs that pass, select \"On, and keep all\". This setting would let you keep video recordings for other purposes, like documentation, tutorials or marketing. There are so many other great settings to explore in the Configurations tab. To learn more about them, check out “Author fast and reliable tests for Xcode Cloud” from WWDC22.\n\nXcode Cloud is a service built into Xcode that’s also available in App Store Connect. It can help you build your app, run tests, upload to the App Store and so much more. All of that happens in the cloud without you using any of you or your team’s devices. I think you’ll find that when it comes to Xcode Cloud, it’s all sun and games. For the Landmarks app, we’ve configured an Xcode Cloud workflow that runs all of the UI automations I just wrote, using the test plan I just created. This plan will run the same way in the cloud as it was run on my simulator, on any number of devices and configurations like English, Arabic, Hebrew, and German on iPhone and iPad.\n\nYou can view a history of your Xcode Cloud runs from within Xcode or in the Xcode Cloud section of App Store Connect. There, you can see an overview of build information, logs, failure descriptions and more.\n\nUsing Xcode Cloud, my entire team can see a history of my runs and download results and video recordings from them. They can do that even if I’m literally in the clouds, and by that I mean on my flight to Sydney.\n\nThere’s so much more to learn about Xcode Cloud. For more advanced configurations, check out “Create practical workflows in Xcode Cloud” from WWDC23. Now that we’ve run our recorded tests using a test plan in multiple configurations, we can review the results and the video recordings using the test report. The Xcode test report has some great tools to help you view, understand and diagnose your test results. It looks like one of our runs failed from the automation I just ran. Guess I can’t pack my bags for Australia just yet.\n\nTo navigate to my failing test, I’ll click the Test button, then I’ll double click the failing run to see a video recording and a description of what just happened.\n\nI can see all of the runs in this test in the runs drop-down. This lets me quickly switch between video recordings of my test running in different configurations, like different languages. Also, fun fact, I can download the video by using a secondary click and choosing Save.\n\nI’ll press Play to start video playback.\n\nAs the video plays, dots showing UI interactions are overlayed on top of the video. These actions are also represented in the timeline below as dots.\n\nLooks like there will be a bit of time before my failure, so let’s skip ahead. I’ll jump straight to the failure moment using the failure diamond on the timeline.\n\nI see a failure message, but it’s hard to say what went wrong. The message says we’re looking for a button called Max’s Australian Adventure. Let’s see what was actually present at the point of failure.\n\nAt the moment of failure, I see an overlay of all of the UI elements that were present right on top of the video recording.\n\nIf I click any of these, I get code recommendations for ways I can address this element in my automation code. I can even hit Show All to see alternative examples and find one that works for me.\n\nI think I see what's wrong. We were expecting a button, but there’s no button here. It's just text. Let me fix that really quick.\n\nI’ll select the sample I want and secondary click to copy it.\n\nThen, I can click View Source to go directly to my tests and paste the new line of code over my existing one.\n\nNow, I can replace the temporary XCUIApplication variable with the app variable for my UI recording, and I’m good to go.\n\nGreat, now this should run as expected. Let me click the test diamond to watch the test rerun.\n\nThis time, I’ll run the test in Arabic to see that the same automation works even when my app is running in a right-to-left layout.\n\nThe automation quickly creates my collection and renames it just as it does in English.\n\nPretty cool.\n\nLooks like the automation passed. Time to finish this up and go on the trip of a lifetime. Maybe my mom and sister can come along to show me around. There’s so much more we can do with the Xcode test report. Luckily, the session “Fix failures faster with Xcode test reports” from WWDC23 really goes in depth and covers it all. It’s amazing how UI automation, accessibility, localization, Xcode Cloud and the test report all work together to increase the quality of your app and make it easier to use for everyone around the world. Bringing these technologies together into a single flow has been such a joy, and I can’t wait to see how it’s used by developers.\n\nYou can learn more about unit testing and Swift testing in the talk “Meet Swift Testing” from WWDC24. If you have additional questions or feedback, you can find us in the Developer Forums. Thanks for following along, and I’ll see you in Australia.",
    "segments": []
  },
  "codeExamples": [
    {
      "timestamp": "7:52",
      "title": "Adding accessibility identifiers in SwiftUI",
      "language": "swift",
      "code": "// Adding accessibility identifiers in SwiftUI\nimport SwiftUI\n\nstruct LandmarkDetailView: View {\n  let landmark: Landmark\n  var body: some View {\n    VStack {\n      Image(landmark.backgroundImageName)\n        .accessibilityIdentifier(\"LandmarkImage-\\(landmark.id)\")\n      \n      Text(landmark.description)\n        .accessibilityIdentifier(\"LandmarkDescription-\\(landmark.id)\")\n    }\n  }\n}"
    },
    {
      "timestamp": "8:19",
      "title": "Adding accessibility identifiers in UIKit",
      "language": "swift",
      "code": "// Adding accessibility identifiers in UIKit\nimport UIKit\n\nstruct LandmarksListViewController: UIViewController {\n  let landmarks: [Landmark] = [landmarkGreatBarrier, landmarkCairo]\n\n  override func viewDidLoad() {\n    super.viewDidLoad()\n\n    for landmark in landmarks {\n      let button = UIButton(type: .custom)\n      setupButtonView()\n                \n      button.accessibilityIdentifier = \"LandmarkButton-\\(landmark.id)\"\n      \n      view.addSubview(button)\n    }\n  }\n}"
    },
    {
      "timestamp": "13:54",
      "title": "Best practice: Prefer accessibility identifiers over localized strings",
      "language": "swift",
      "code": "// Example SwiftUI view\nstruct CollectionDetailDisplayView: View {\n  var body: some View {\n    ScrollView {\n      Text(collection.name)\n        .font(.caption)\n        .accessibilityIdentifier(\"Collection-\\(collection.id)\")\n    }\n  }\n}\n\n// Example of a worse XCUIElementQuery\nXCUIApplication().staticTexts[\"Max's Australian Adventure\"]\n\n// Example of a better XCUIElementQuery\nXCUIApplication().staticTexts[\"Collection-1\"]"
    },
    {
      "timestamp": "14:09",
      "title": "Best practice: Keep queries as concise as possible",
      "language": "swift",
      "code": "// Example SwiftUI view\nstruct CollectionDetailDisplayView: View {\n  var body: some View {\n    ScrollView {\n      Text(collection.name)\n        .font(.caption)\n        .accessibilityIdentifier(\"Collection-\\(collection.id)\")\n    }\n  }\n}\n\n// Example of a worse XCUIElementQuery\nXCUIApplication().scrollViews.staticTexts[\"Collection-1\"]\n\n// Example of a better XCUIElementQuery\nXCUIApplication().staticTexts[\"Collection-1\"]"
    },
    {
      "timestamp": "14:21",
      "title": "Best practice: Prefer generic queries for dynamic content",
      "language": "swift",
      "code": "// Example SwiftUI view\nstruct CollectionDetailDisplayView: View {\n  var body: some View {\n    ScrollView {\n      Text(collection.name)\n        .font(.caption)\n        .accessibilityIdentifier(\"Collection-\\(collection.id)\")\n    }\n  }\n}\n\n// Example of a worse XCUIElementQuery\nXCUIApplication().staticTexts[\"Max's Australian Adventure\"]\n\n// Example of a better XCUIElementQuery\nXCUIApplication().staticTexts.firstMatch"
    },
    {
      "timestamp": "15:49",
      "title": "Add validations to a test case",
      "language": "swift",
      "code": "// Add validations to the test case\nimport XCTest\n\nclass LandmarksUITests: XCTestCase {\n\n  func testGreatBarrierAddedToFavorites() {\n    let app = XCUIApplication()\n    app.launch()\n    app.cells[\"Landmark-186\"].tap()\n    XCTAssertTrue(\n      app.staticTexts[\"Landmark-186\"].waitForExistence(timeout: 10.0)),\n      \"Great Barrier exists\"\n    )\n\n    let favoriteButton = app.buttons[\"Favorite\"]\n    favoriteButton.tap()\n    XCTAssertTrue(\n      favoriteButton.wait(for: \\.value, toEqual: true, timeout: 10.0),\n      \"Great Barrier is a favorite\"\n    )\n  }\n}"
    },
    {
      "timestamp": "16:36",
      "title": "Set up your device for test execution",
      "language": "swift",
      "code": "// Set up your device for test execution\nimport XCTest\nimport CoreLocation\n\nclass LandmarksUITests: XCTestCase {\n\n  override func setUp() {\n    continueAfterFailure = false\n    \n    XCUIDevice.shared.orientation = .portrait\n    XCUIDevice.shared.appearance = .light\n      \n    let simulatedLocation = CLLocation(latitude: 28.3114, longitude: -81.5535)\n    XCUIDevice.shared.location = XCUILocation(location: simulatedLocation)\n  }\n  \n}"
    },
    {
      "timestamp": "16:54",
      "title": "Launch your app with environment variables and arguments",
      "language": "swift",
      "code": "// Launch your app with environment variables and arguments\nimport XCTest\n\nclass LandmarksUITests: XCTestCase {\n\n  func testLaunchWithDefaultCollection() {\n    let app = XCUIApplication()\n    app.launchArguments = [\"ClearFavoritesOnLaunch\"]\n    app.launchEnvironment = [\"DefaultCollectionName\": \"Australia 🐨 🐠\"]\n    app.launch()\n\n    app.tabBars.buttons[\"Collections\"].tap()\n    XCTAssertTrue(app.buttons[\"Australia 🐨 🐠\"].waitForExistence(timeout: 10.0))\n  }\n}"
    },
    {
      "timestamp": "17:04",
      "title": "Launch your app using custom URL schemes",
      "language": "swift",
      "code": "// Launch your app using custom URL schemes\nimport XCTest\n\nclass LandmarksUITests: XCTestCase {\n\n  func testOpenGreatBarrier() {\n    let app = XCUIApplication()\n    let customURL = URL(string: \"landmarks://great-barrier\")!\n    app.open(customURL)\n\n    XCTAssertTrue(app.wait(for: .runningForeground, timeout: 10.0))\n    XCTAssertTrue(app.staticTexts[\"Great Barrier Reef\"].waitForExistence(timeout: 10.0))\n  }\n}"
    },
    {
      "timestamp": "17:12",
      "title": "Launch your app using custom URL schemes and the system default app",
      "language": "swift",
      "code": "// Launch your app using custom URL schemes\nimport XCTest\n\nclass LandmarksUITests: XCTestCase {\n\n  func testOpenGreatBarrier() {\n    let app = XCUIApplication()\n    let customURL = URL(string: \"landmarks://great-barrier\")!\n    XCUIDevice.shared.system.open(customURL)\n\n    XCTAssertTrue(app.wait(for: .runningForeground, timeout: 10.0))\n    XCTAssertTrue(app.staticTexts[\"Great Barrier Reef\"].waitForExistence(timeout: 10.0))\n  }\n}"
    },
    {
      "timestamp": "17:13",
      "title": "Perform an accessibility audit during an automation",
      "language": "swift",
      "code": "// Perform an accessibility audit during an automation\nimport XCTest\n\nclass LandmarksUITests: XCTestCase {\n  \n  func testPerformAccessibilityAudit() {\n    let app = XCUIApplication()\n    try app.performAccessibilityAudit()\n  }\n\n}"
    }
  ],
  "resources": {
    "resourceLinks": [
      {
        "title": "Design",
        "url": "https://developer.apple.com/design/"
      },
      {
        "title": "Delivering an exceptional accessibility experience",
        "url": "https://developer.apple.com/documentation/Accessibility/delivering_an_exceptional_accessibility_experience"
      },
      {
        "title": "Improving code assessment by organizing tests into test plans",
        "url": "https://developer.apple.com/documentation/Xcode/organizing-tests-to-improve-feedback"
      },
      {
        "title": "Performing accessibility testing for your app",
        "url": "https://developer.apple.com/documentation/Accessibility/performing-accessibility-testing-for-your-app"
      },
      {
        "title": "Documentation",
        "url": "https://developer.apple.com/documentation/"
      },
      {
        "title": "Forums",
        "url": "https://developer.apple.com/forums/"
      },
      {
        "title": "Apple Design Awards",
        "url": "https://developer.apple.com/design/awards/"
      }
    ],
    "hdVideo": "https://devstreaming-cdn.apple.com/videos/wwdc/2025/344/6/d83ce906-0fb6-484b-a0f2-4f678161d5b8/downloads/wwdc2025-344_hd.mp4?dl=1",
    "sdVideo": "https://devstreaming-cdn.apple.com/videos/wwdc/2025/344/6/d83ce906-0fb6-484b-a0f2-4f678161d5b8/downloads/wwdc2025-344_sd.mp4?dl=1"
  },
  "relatedVideos": [
    {
      "id": "10179",
      "year": "2024",
      "title": "Meet Swift Testing",
      "url": "https://developer.apple.com/videos/play/wwdc2024/10179"
    },
    {
      "id": "10036",
      "year": "2023",
      "title": "Build accessible apps with SwiftUI and UIKit",
      "url": "https://developer.apple.com/videos/play/wwdc2023/10036"
    },
    {
      "id": "10278",
      "year": "2023",
      "title": "Create practical workflows in Xcode Cloud",
      "url": "https://developer.apple.com/videos/play/wwdc2023/10278"
    },
    {
      "id": "10175",
      "year": "2023",
      "title": "Fix failures faster with Xcode test reports",
      "url": "https://developer.apple.com/videos/play/wwdc2023/10175"
    },
    {
      "id": "10035",
      "year": "2023",
      "title": "Perform accessibility audits for your app",
      "url": "https://developer.apple.com/videos/play/wwdc2023/10035"
    },
    {
      "id": "110361",
      "year": "2022",
      "title": "Author fast and reliable tests for Xcode Cloud",
      "url": "https://developer.apple.com/videos/play/wwdc2022/110361"
    },
    {
      "id": "10119",
      "year": "2021",
      "title": "SwiftUI Accessibility: Beyond the basics",
      "url": "https://developer.apple.com/videos/play/wwdc2021/10119"
    }
  ],
  "extractedAt": "2025-07-18T09:39:32.046Z"
}