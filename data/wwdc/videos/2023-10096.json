{
  "id": "10096",
  "year": "2023",
  "url": "https://developer.apple.com/videos/play/wwdc2023/10096/",
  "title": "Build great games for spatial computing",
  "speakers": [],
  "duration": "",
  "topics": [
    "Graphics & Games"
  ],
  "hasTranscript": true,
  "hasCode": false,
  "transcript": {
    "fullText": "♪ Mellow instrumental hip-hop ♪ ♪ Hi! I am Tricia Gray, and I work on the RealityKit Tools team.\n\nWelcome to \"Build great games for spatial computing.\" I am really excited to talk to you today about making games for this new device.\n\nSpatial computing makes all sorts of new game types possible.\n\nIt has unique rendering, audio, and input characteristics.\n\nYou have several choices when it comes to which frameworks and tools you can use to build games on it, and that includes RealityKit.\n\nBut first, I'll give you an idea of what types of games are possible on this new platform.\n\nThis is a standalone spatial computing device.\n\nIt has high-resolution screens, a wide field of view, and a great refresh rate.\n\nThe Spatial Audio is amazing.\n\nAnd there's LiDAR that tracks both hand movements and the shape of the room around the player.\n\nAnd players can stay connected to their surroundings using the device's high-quality passthrough.\n\nThis has exciting possibilities and lets you create a wide variety of different game types.\n\nYou can build games that span a spectrum of immersion, all depending on how much of the player's attention you want to capture.\n\nAll apps and games start in the Shared Space.\n\nThis means that your game can live in space together with other games and apps and the player's surroundings.\n\nThere might be a virtual chessboard on the player's actual desktop representing an active game of chess, or a virtual pet sitting on the floor.\n\nAll of these apps live together, and the player can interact with whichever one they want.\n\nYou can put all attention on your game when you move into Full Space.\n\nThis closes all other windows and volumes, focusing the experience on your content, while still keeping the player connected to their surroundings through passthrough.\n\nThis might be suitable for an action game -- something you're actively playing but that still interacts with the real world.\n\nYou can have spaceships coming through a hole in the wall, for example.\n\nA fully immersive experience is when the game takes over the whole view.\n\nInstead of your room, there's an environment and you can no longer see the real world.\n\nOf course, you can also make traditional 2D games.\n\nThey run in a virtual window, and the player can make that window as big or as small as they want.\n\nIt doesn't even have to be a vertical window, it could be a flat surface laying on the ground.\n\nThey could hang it on the wall or put it on a desk, or have it as the largest screen they've ever had right in front of their face.\n\nPlayers can interact with your game just as they would on iOS, but instead of touching the screen, they'll look at an object and tap their fingers together to select it.\n\nYou can also connect a Bluetooth controller or a keyboard, just as you can on iOS, and the passthrough is helpful here because you can look down and see the controller you are using.\n\nYou can also spice up a 2D game by adding some 3D elements to it.\n\nFor example, your window has real depth, so you can render your objects in separate layers and get a real parallax effect.\n\nYou can also have elements that come out of the plane, such as smoke or sparks.\n\nOr you can add support for custom hand gestures.\n\nWith all these options, you have a lot to think about.\n\nAs you design your game, think about how you can take advantage of these new opportunities for gameplay experiences, from having a giant high-resolution screen to having something personal that you can play in your own room.\n\nYour game can appear on the player's desk.\n\nThey can place it on the wall.\n\nSomething can fly out and land in the player's hands.\n\nYou can make use of the real world around them or transport them into an entirely different place.\n\nRendering, audio, and input work differently on this device than you might be used to on other platforms.\n\nWhen you're running in a Shared Space, the content from your game is drawn together with content from other apps, system UI, and passthrough.\n\nSince the rendering is shared, the frameworks ensure that all apps are good citizens and their rendering doesn't interfere with other apps.\n\nIn this mode, you can use surface shaders and geometry shaders through MaterialX.\n\nRendering on xrOS works a little differently than you are used to.\n\nInstead of rendering every pixel, you describe what should be rendered -- all the models, textures, and shaders -- and then the device renders it automatically for each eye.\n\nAnother benefit of the platform rendering for your game is that it can apply dynamic foveation to increase the resolution.\n\nDynamic foveation is a technique where the renderer uses higher resolution at the part of the display where the player's eyes are looking.\n\nThis means you get crisper resolution in those spots without paying the cost of rendering the whole scene, all without having to do any of the hard work.\n\nBy default, RealityKit renders your objects in such a way that they blend in realistically with the real-world objects around them.\n\nRealityKit will sample the actual lighting in the player's room and apply that same lighting to the objects you render.\n\nFor materials, RealityKit uses a physically based lighting model with typical parameters such as roughness, specular, and metallic.\n\nThis, together with the sampled lighting, gives you a realistic look.\n\nBut you can choose where you want to be on the scale from realistic to fantastical.\n\nInstead of using the built-in PBR shader, you can create customized shader content using MaterialX and edit the shader graph in Reality Composer Pro or other graphic packages.\n\nYou can also assign custom IBLs to your object for custom lighting effects.\n\nAnother consideration is that there are some systemwide effects that get applied to rendered content.\n\nThe purpose of this is to make your game work better with other apps and protect the player.\n\nDepth mitigation makes your content slightly transparent when it's hidden behind objects in a player's surroundings.\n\nThis gets rid of the feeling that objects are floating in the room.\n\nNear-field vignetting fades your content when the player gets too close to it.\n\nThis prevents issues with your content clipping against the near plane.\n\nBreakthrough allows someone who is approaching you to break through the rendered view, so they don't run into you without you noticing.\n\nFinally, grounding shadows are added to rendered objects when they are placed near real-world objects to make them feel more integrated into the scene.\n\nFully immersive rendering works similar to shared rendering, but in this case, instead of sharing the screen with passthrough and other apps, your app is the only thing visible.\n\nIn this mode, you render an environment that replaces the real-world view around the player.\n\nRendering in this mode works similar to rendering in the shared mode.\n\nYou still describe the scene and the device renders it.\n\nBut since you control everything the player sees, you have more freedom.\n\nFor example, you don't have to use the same lighting environment as the room the player is in.\n\nYou can make the world as bright or as dark as you want.\n\nThe strength of the device lies in the shared mode, but the fully immersive experience is there when you want to transport the player to a different place.\n\nIf you'd like to write your own engine, the CompositorServices API gives you access to Metal rendering on xrOS.\n\nYou can combine it with ARKit, which adds world tracking and hand tracking to create a fully immersive experience.\n\nIn this mode, you have full access to the screen and render the scene for each eye.\n\nYou can use fully custom Metal shaders and post processors.\n\nThis enables you to completely replace real-world content with your own virtual content.\n\nPassthrough and other apps are hidden.\n\nFor more information on this, check out \"Discover Metal for immersive apps.\" Audio can be immersive too.\n\nxrOS uses Spatial Audio to bring objects to life in the player's space, automatically matching the reverb and the real room acoustics.\n\nIf you play audio using standard iOS audio APIs such as AVAudioEngine, the audio will be positioned relative to the app window.\n\nIf you want sound to come from different objects in the scene in the player's space, you should play the audio through RealityKit on specific entities in your scene.\n\nYou also have the option of doing your own audio using any Apple or external API.\n\nIf you want the audio to be head tracked, you need to use ARKit to get the player's head position.\n\nIn addition to graphics and audio, interaction is another key part of an immersive experience.\n\nAfter all, every game needs input, and this platform offers multiple ways to interact with the device.\n\nYou can get input events on the objects in your scene through SwiftUI as well as other standard system gestures such as dragging and magnifying.\n\nThis is based on the physics collision.\n\nTo make the gestures work on your objects, they need to have both a CollisionComponent, which provides the collision shape, as well as an InputTargetComponent, which marks them as interactable.\n\nSpatial input can feel pretty magical for players, but you have other options for game input too.\n\nEven game controllers! While system Look & Tap gestures feel natural, you only have one set of eyes to look with and only two hands that can tap, pinch, or grab.\n\nSome games need more points of input.\n\nOne possibility is to use a standard Bluetooth controller.\n\nxrOS supports trackpads, mice, and keyboards, as well as Bluetooth-based game controllers.\n\nThis can be a good option for traditional games.\n\nAnd xrOS also allows for more unconventional input, such as using your own body as a controller.\n\nYou can use hand tracking to let the player grab virtual objects or implement custom gestures, such as pointing at an object or karate chopping them.\n\nYou access hand tracking through ARKit, and the device will ask the player for permission, same as when an app wants to use your location or microphone.\n\nThere are some things to consider when designing this input.\n\nHands can only be tracked when they are visible to the camera.\n\nReally fast hand movements can be hard to track.\n\nTake that into account.\n\nWhen you are working in a Full Space, you can request scene understanding.\n\nScene understanding provides a virtual mesh representing the room around the player.\n\nIt can also do plane detection to find horizontal and vertical surfaces.\n\nYou can also get the materials of those surfaces, whether it's carpet or wood.\n\nThis lets you use the room itself as part of the input to your game.\n\nJust as with hand tracking, this requires permission from the player.\n\nWith all the input options, you have to figure out what is right for your game.\n\nUsing the player's body for direct input is a great way of engaging them.\n\nBut holding your hands up and doing gestures is also something that can get tiring over time.\n\nIf your game will be played for long stretches of time or require a lot of quick actions, think about how you can make use of indirect gestures and gaze.\n\nThat way players can rest their hands comfortably on their lap, and Look & Tap instead of moving their hands.\n\nThe device is meant to be something you use every day, so comfort is important.\n\nAnd if it makes sense, you can also go to a more traditional game controller.\n\nThis platform supports all the multiplayer and networking capabilities you are familiar with from other platforms.\n\nWeb-based networking, low-level socket-based networking, and Multipeer Connectivity are all available to you.\n\nSharePlay also makes it easy for the player to socialize in a more intimate way.\n\nYou can even build games using networking that allows some players to play on iPhones or iPads and still connect to this great device.\n\nImagine a dominos game with your friend that has an iPad, and they have a 2D experience while you have a rich, immersive 3D experience.\n\nNow that you know a little bit more about this as a gaming device, here are the frameworks you can use to create games.\n\nDepending on whether you want to make a 2D game, a game that lives in Volume, or a fully immersive game, there are different options available to you, such as using RealityKit, our immersive framework, or writing something directly on top of Metal, or even using Unity.\n\nIf you have already made a game for iPhone or iPad, in most cases, your game will automatically run on the device in a virtual window, using Look & Tap to interact.\n\nNote that this applies to compatible 3D games too.\n\nThey will run in a flat window on the device.\n\nIf you want your game to be stereoscopic, you must use the spatial computing APIs.\n\nBeing able to run compatible games is great, but if you want to take full advantage of the device, build your game to target it.\n\nThat way you can use gestures for input, or add 2.5D elements such as perspective or volumetric smoke.\n\nYou can build 2D games for the device using a 2D framework such as SwiftUI or SpriteKit.\n\nYou can use Unity to build games for xrOS.\n\nThis is a great option if you already have a Unity game that you want to port, or if you are a Unity developer.\n\nIf you want to learn more about using Unity, go to the sessions \"Bring your Unity VR app to a fully immersive space\" or \"Create immersive Unity apps.\" Finally, there is RealityKit, Apple's real-time rendering framework for building immersive spatial experiences.\n\nThe API has a lot of new features to make it a great way of creating 3D games for xrOS.\n\nRealityKit supports all the features you need to make great games.\n\nThere is an entity component system for custom behaviors, and an extensibility along with physics, animation, particles, and audio support.\n\nOn the rendering side, RealityKit supports both USD models as well as custom meshes.\n\nFor grounding your objects in the world, there are MaterialX and IBL lighting.\n\nAttachments, a new feature which allows you to connect rich SwiftUI directly to your RealityKit objects.\n\nUsing SwiftUI, you can mix passthrough and rendered content in various ways using features such as Windows, Volumes, Spaces, Anchors, and Portals.\n\nYou can use system gestures for input, or you can use ARKit to access hand tracking and scene understanding.\n\nTo start building your game for xrOS, you create a new Xcode project from the xrOS template.\n\nThis gives you a SwiftUI window with a RealityView inside of it.\n\nThe RealityView in the SwiftUI hierarchy holds the 3D rendering and simulation for your game.\n\nIf you're not familiar with SwiftUI yet, it is worth it to learn a little bit about it.\n\nBy default, your 3D content appears in a volumetric box formed by the window.\n\nYour content is confined to that window and will follow along as it moves.\n\nRealityKit is a Swift API.\n\nSwift can be a great language for building games, but if you want to use another language, you can.\n\nYou just create a bridge between that language and the Swift API.\n\nXcode comes with a Simulator.\n\nYou can start developing your games right away without having a device.\n\nOf course, testing it on a real device is always best.\n\nYour 3D content will by default be displayed in a SwiftUI window.\n\nOne of the first things you will want to do as a game developer is to break out of that window and draw content in the player's surroundings.\n\nYou have some different options for doing that.\n\nYou can use a volume.\n\nVolumes are similar to windows, with one important difference.\n\nWith windows, the player controls the size.\n\nThey can drag the corner and make it as big or as small as they like, and your content has to adapt.\n\nIf the window is too small for your content, your content will be clipped.\n\nWith Volumes, it's the other way around.\n\nWith Volumes, you say, \"I want the box to be this big, this high, and this deep.\" The player can still put that box wherever they want in the world, but the box will always be the same size.\n\nSo you can make sure that the box is big enough to fit your entire experience, and you can be sure that the content doesn't clip.\n\nIf you don't want to use a box at all, you can use a space.\n\nThis allows you to render content all around the player in the real world.\n\nFor example, you can surround the player with buzzing bees.\n\nThere are different kinds of spaces corresponding to the different game types.\n\nYou can use a Shared Space to run together with other apps, or a Full Space if you want your game to be the only thing running.\n\nAnchors let you anchor your scene to an object in the real world and follow it around as it moves.\n\nYou can use a horizontal or a vertical surface anchor to anchor the entity to a desk or a wall.\n\nThere are also hand anchors that let you anchor content to the player's hands.\n\nPortals allow you to punch a hole in the player's reality to create your own fantastic reality.\n\nYou can anchor a portal to a real wall and have that portal cut a hole in the wall that lets you peek into a rendered world inside the hole.\n\nYou can render whatever you want inside that portal, and the objects inside the portal can emerge into the real world too.\n\nRealityKit can load and render USD files.\n\nOne of the easiest ways to get started with volumetric content is to assemble scenes out of premade objects, but for that, you need some kind of visual tool.\n\nReality Composer Pro is a tool that comes bundled with Xcode.\n\nIt lets you load USD models and preview how they will look on the device.\n\nWhen you build your project with Reality Composer Pro, your assets are automatically optimized for use on the device.\n\nYou can learn more about Reality Composer Pro in these sessions.\n\nI hope this session was a helpful game-development roadmap for spatial computing.\n\nBe sure to take a deeper dive in the multiple framework sessions available.\n\nThis is a great platform to socialize and play games with others.\n\nI can't wait to see what you develop for it.\n\n♪",
    "segments": []
  },
  "resources": {
    "resourceLinks": [
      {
        "title": "Design",
        "url": "https://developer.apple.com/design/"
      },
      {
        "title": "Documentation",
        "url": "https://developer.apple.com/documentation/"
      },
      {
        "title": "Forums",
        "url": "https://developer.apple.com/forums/"
      },
      {
        "title": "Apple Design Awards",
        "url": "https://developer.apple.com/design/awards/"
      }
    ],
    "hdVideo": "https://devstreaming-cdn.apple.com/videos/wwdc/2023/10096/6/F177C6E8-2AAC-400D-B584-FC7D76E4516F/downloads/wwdc2023-10096_hd.mp4?dl=1",
    "sdVideo": "https://devstreaming-cdn.apple.com/videos/wwdc/2023/10096/6/F177C6E8-2AAC-400D-B584-FC7D76E4516F/downloads/wwdc2023-10096_sd.mp4?dl=1"
  },
  "relatedVideos": [
    {
      "id": "10093",
      "year": "2023",
      "title": "Bring your Unity VR app to a fully immersive space",
      "url": "https://developer.apple.com/videos/play/wwdc2023/10093"
    },
    {
      "id": "10088",
      "year": "2023",
      "title": "Create immersive Unity apps",
      "url": "https://developer.apple.com/videos/play/wwdc2023/10088"
    },
    {
      "id": "10089",
      "year": "2023",
      "title": "Discover Metal for immersive apps",
      "url": "https://developer.apple.com/videos/play/wwdc2023/10089"
    },
    {
      "id": "10094",
      "year": "2023",
      "title": "Enhance your iPad and iPhone apps for the Shared Space",
      "url": "https://developer.apple.com/videos/play/wwdc2023/10094"
    },
    {
      "id": "10202",
      "year": "2023",
      "title": "Explore materials in Reality Composer Pro",
      "url": "https://developer.apple.com/videos/play/wwdc2023/10202"
    },
    {
      "id": "10083",
      "year": "2023",
      "title": "Meet Reality Composer Pro",
      "url": "https://developer.apple.com/videos/play/wwdc2023/10083"
    }
  ],
  "extractedAt": "2025-07-18T10:29:51.168Z"
}